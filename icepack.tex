\documentclass{article}

\usepackage{amsmath}
%\usepackage{amsfonts}
\usepackage{amsthm}
%\usepackage{amssymb}
%\usepackage{mathrsfs}
%\usepackage{fullpage}
%\usepackage{mathptmx}
%\usepackage[varg]{txfonts}
\usepackage{natbib}
\usepackage{color}
\usepackage[charter]{mathdesign}
\usepackage[pdftex]{graphicx}
%\usepackage{float}
%\usepackage{hyperref}
%\usepackage[modulo, displaymath, mathlines]{lineno}
%\usepackage{setspace}
%\usepackage[titletoc,toc,title]{appendix}
\usepackage{lineno}
\linenumbers
%\doublespacing

\theoremstyle{definition}
\newtheorem*{defn}{Definition}
\newtheorem*{exm}{Example}

\theoremstyle{plain}
\newtheorem*{thm}{Theorem}
\newtheorem*{lem}{Lemma}
\newtheorem*{prop}{Proposition}
\newtheorem*{cor}{Corollary}

\newcommand{\argmin}{\text{argmin}}
\newcommand{\ud}{\hspace{2pt}\mathrm{d}}
\newcommand{\bs}{\boldsymbol}
\newcommand{\PP}{\mathsf{P}}

\title{\emph{icepack}: a novel glacier flow modeling package}
\author{Daniel Shapero, Jessica Badgeley, Andrew Hoffmann}
\date{}

\begin{document}

\tableofcontents
\newpage

\maketitle

\begin{abstract}
In this paper we introduce a new software package called \emph{icepack} for modeling the flow of glaciers and ice sheets.
Icepack is built on the finite element modeling library Firedrake, which uses the domain-specific language UFL for describing weak forms of partial differential equations.
The diagnostic models in icepack are formulated through action principles that are specified in UFL.
The components of each action functional can be substituted for different forms of the user's choosing, which makes it easy to experiment with the model physics.
Many post-processing and analysis tasks on simulation results also amount to the evaluation of some functional.
By using a variational formulation of the model physics, the specification of a problem and the analysis of the solution employ the same conceptual vocabulary.
A third advantage of variational principles is that the action functional itself can be used to define a solver convergence criterion that is independent of the mesh and requires little tuning on the part of the user.
Icepack includes the 2D shallow ice and shallow stream models and a novel implementation of the 3D Blatter-Pattyn model.
Finally, icepack implements a Gauss-Newton solver for inverse problems that runs substantially faster than the standard BFGS method used in the glaciological literature.
The overall design philosophy of icepack is to be as usable as possible for a wide a swathe of the glaciological community, including both experts and novices in computational science.
\end{abstract}

\section{Introduction}

Numerical modeling has become an essential part of the workflow of glaciologists across all disciplines.
We highlight four main uses of glacier models in the literature:
\begin{enumerate}
    \item predicting future glacier extent and estimating the sea-level rise contribution from glacier dynamics,
    \item exploring aspects of glacier physics, such as hydrology and calving, that are not completely understood,
    \item estimating unobservable quantities, such as bed friction or rheology, from observational data, and
    \item reconstructing what glaciers of the near- or distant-past may have looked like.
\end{enumerate}
Nearly all glaciologists, from graduate students to senior researchers, need to use numerical models at some point in their career.
Several glacier flow models already exist and are effective in the hands of experts.
These models are usually written in compiled programming languages such as C, C++, and Fortran for reasons of computational efficiency.
Many researchers in glaciology, however, receive little or no formal programming training, much less in these languages, and are instead self-taught in either Python or MATLAB.
The ubiquity of C, C++, and Fortran in scientific computing can create a barrier to entry for glaciologists who are not experts in high-performance computing.
Our goal is to make a tool that will be both accessible to non-experts and useful for experts.

The glacier flow modeling package closest in spirit to icepack is VarGlaS \citep{brinkerhoff2013data}.
VarGlaS is implemented using the finite element modeling package FEniCS \citep{logg2012automated}, whereas icepack is built on top of Firedrake.
The Firedrake project began as an outgrowth of FEniCS.
Both packages share a similar goal of saving users from manually writing low-level code for assembling the systems of equations that discretize their physics model.
Instead, users describe the weak form of the partial differential equations they wish to solve using a high-level domain-specific language (DSL) called the \emph{Unified Form Language} or UFL \citep{alnaes2014unified}.
This DSL is embedded entirely into Python, i.e. the complete syntax of UFL can be mapped directly onto overloaded operators in the Python programming language.
Both FEniCS and Firedrake then generate optimized C or C++ code to assemble the discretized system of equations from this symbolic description of the problem \citep{kirby2006compiler, rathgeber2016firedrake}.
Combining a DSL and a code generator frees users from the very error-prone process of writing these assembly kernels themselves, and makes the syntax of the code align closer to the syntax of written mathematical expressions.
Additionally, having a high-level symbolic description of the problem makes it possible to automatically derive tangent linear models and adjoints \citep{mitusch2019dolfin}.

Icepack improves upon the groundwork laid in VarGlaS in three main respects.
First, icepack includes a simple 3D flow model that uses several features only available in Firedrake: extruded meshes and tensor product finite elements \citep{bercea2016structure, mcrae2016automated}.
This model will be described in section \S\ref{sec:physics-hybrid-model}.
Second, the architecture of icepack is designed to make it easy for users to alter the various physics components, such as the rheology and basal friction, of any of the models included.
The software design that made this possible is discussed in section \S\ref{sec:physics-substitution}.
Finally, the inverse solver in icepack uses the Gauss-Newton method, which converges faster and more reliably than the BFGS method used in VarGlaS; see section \S\ref{sec:numerics-inverse-solvers}.

The two main components of a glacier flow model are a \emph{diagnostic} and a \emph{prognostic} equation.
The diagnostic equation prescribes the ice velocity through a time-independent, nonlinear, elliptic partial differential equation.
The inputs to the diagnostic equation are the ice thickness, surface elevation, velocity at the inflow boundary, rheology, and bed friction coefficient.
The output of the diagnostic equation is the ice velocity throughout the entire domain.
The prognostic equation prescribes how the ice thickness evolves through conservation of mass.
The inputs to the prognostic equation are the current value of the ice thickness, velocity, and the surface and basal mass balance.
The output is the ice thickness at the subsequent timestep.
Mathematically, these two coupled PDEs can be thought of as a differential-algebraic equation.

The rheology and friction coefficient are functions of other fields that have their own evolution equations.
For example, the rheology is a function of temperature, englacial water content, and damage from crevassing.
Likewise, the friction coefficient can be described in terms of the subglacial water pressure and a roughness factor for the underlying bedrock.
The diagnostic and prognostic equations can then be supplemented with evolution equations for these fields, for example the heat equation for temperature, or a hydrology model for subglacial water pressure.


\section{Physics}

\begin{table}[h]
    \begin{tabular}{l|l}
        Symbol & Meaning \\
        \hline
        $h$ & thickness \\
        $b$ & bed elevation  \\
        $s$ & surface elevation  \\
        $d$ & water depth \\
        $u$ & velocity \\
        $\dot a_s$ & surface mass balance \\
        $\dot a_b$ & basal mass balance \\
        $\dot\varepsilon$ & strain rate \\
        $C$ & bed friction coefficient \\
        $A$ & rheology coefficient \\
        $\nu$ & unit outward normal \\
        $J$ & action functional
    \end{tabular}
    \caption{Mathematical symbols}
\end{table}

\begin{table}[h]
    \begin{tabular}{l|l}
        Symbol & Meaning \\
        \hline
        $n$ & Glen's flow law exponent \\
        $m$ & Weertman sliding law exponent \\
        $\rho_I$ & ice density \\
        $\rho_W$ & seawater density \\
        $g$ & gravitational acceleration
    \end{tabular}
    \caption{Physical constants}
\end{table}


\subsection{Prognostic model}

The \emph{prognostic model} or \emph{mass transport equation} (the two terms are synonymous) describes how the ice thickness changes in time.
The prognostic model is a conservative advection equation:
\begin{equation}
    \frac{\partial h}{\partial t} + \nabla\cdot hu = \dot a_s - \dot a_b,
\end{equation}
where $\dot a_s$ and $\dot a_b$ are the surface and basal mass balance.
The thickness is represented using continuous, piecewise polynomial basis functions in each cell of the mesh.
The ice thickness and bed elevation are used to update the surface elevation at every timestep, and we need the surface gradient to calculate the driving stress.
The current prognostic model implementation in icepack assumes continuous basis functions because this makes for the most straightforward calculation of the ice surface slope, which is part of the driving stress.
We have not yet implemented a solver that works for discontinuous basis functions, but this extension is completely feasible within our framework and may come in a future release of icepack.

The surface elevation is calculated at each timestep of a simulation as
\begin{equation}
    s = \max\{b + h, (1 - \rho_I / \rho_W)h\},
\end{equation}
the first case corresponding to grounded ice and the second case corresponding to floating ice.
In the immediate vicinity of the grounding line, the assumption that the floating ice is in hydrostatic equilibrium with the ocean fails.
Most models assume hydrostasy and icepack does as well.
Elmer/Ice, on the other hand, solves a contact problem for the moving upper and lower ice surfaces and thus can accurately model non-hydrostatic ice shelves \citep{gagliardini2013capabilities}.
We have not implemented this feature but support for non-hydrostatic ice shelves may come in a future release of icepack.


\subsection{Diagnostic model}

There are four \emph{diagnostic} or \emph{momentum transport} models implemented in icepack.
For each of the diagnostic models, we use a formulation of the physics based on a \emph{minimization} or \emph{action principle} \citep{dukowicz2010consistent}.
Action principles are completely equivalent to the usual weak form of a partial differential equation but have certain numerical advantages that we will describe below.

The most complex and most physically accurate model is the \emph{first-order} or \emph{Blatter-Pattyn} approximation, a 3D system describing the horizontal velocity \citep{blatter1995velocity, pattyn2003new}.
(In icepack we refer to our implementation of this equation as a \emph{hybrid model} as it includes both shear and plug flow modes, described below.)
The only approximation that the first-order model makes is that the flow has a low aspect ratio -- the thickness of the glacier is much less than its horizontal extent.
This approximation may be questionable around, say, the main trunk of Jakobshavn Isbrae in Greenland, which flows through a very deep and narrow trough.
Even Jakobshavn has an aspect ratio on the order of 1/5 and almost all glacier flows have an aspect ratio less than 1/10 or even 1/20.

From the first-order model, two approximations are possible.
First, the \emph{shallow ice approximation} (SIA) comes from assuming that vertical shear is the dominant mode of ice flow.
The SIA model \citep{hutter1981effect} describes the interior of ice sheets well, where flow can be simply described as bed-parallel shear and surface and basal slopes are small.
This approximation breaks down near ice divides, where vertical velocities dominate, and near ice margins, where basal sliding can be a large fraction of the surface speed.
Second, one could assume that ice flow is purely by horizontal extension and that the surface and bed velocities are practically the same.
This is called the \emph{shallow stream approximation} (SSA).
The SSA model describes the fast-flowing margins of the ice sheet best, encompassing grounded ice streams or floating ice shelves \citep{macayeal1989large}.
Finally, for floating ice, the shallow stream approximation simplifies further to the \emph{shallow shelf approximation}.
The shallow shelf model has no bed friction and the ice surface elevation can be eliminated from the system.

All the diagnostic models inherit a fundamental nonlinearity in the mechanics of ice flow.
For a Newtonian viscous fluid, the stress tensor $\tau$ and the strain rate tensor $\dot\varepsilon$ are linearly proportional to each other.
Glaciers, however, have a nonlinear constitutive relation:
\begin{equation}
    \dot\varepsilon = A|\tau|^{n - 1}\tau
\end{equation}
where $A$ is the \emph{fluidity} and $n$ is the \emph{Glen flow law exponent} \citep{cuffey2010physics}.
The most commonly-used value of the flow law exponent is $n \approx 3$ as determined from laboratory experiments.

All of the diagnostic models in icepack are described through \emph{variational} or \emph{action} principles \citep{dukowicz2010consistent}.
Rather than describe the velocity as the weak solution of a nonlinear PDE, an action principle instead states that the velocity minimizes a functional called the action.
The action consists of four terms:
\begin{align}
    & \text{action} = \iint\text{stress} \times \text{strain rate}\ud z\ud x - \int\text{basal friction} \times \text{sliding velocity}\ud x \nonumber \\
    & \quad - \iint\text{surface slope}\times\text{velocity}\ud z\ud x - \iint\text{ocean pressure}\times\text{velocity}\ud z\ud \gamma
    \label{action-functional}
\end{align}
where $\ud z\ud x$ denotes integration over the entire glacier, $\ud x$ denotes integration over the glacier footprint, and $\ud z\ud\gamma$ over the side wall boundary.
The action has units of power (energy/time) and can be related to the rate of decrease of the thermodynamic free energy.
Moreover, the energy lost to viscous and frictional heating can be calculated from the action and its Legendre transform.
The action principle can be viewed as a consequence of the Onsager reciprocity relations for systems near to equilibrium \citep{de2013non}.

Every diagnostic model in icepack is encapsulated in its own Python class.
The key responsibility of the model classes is to take in the input fields -- the ice thickness, velocity, etc. -- and return a symbolic description of the action functional in UFL.

The action principle is especially useful for designing a robust numerical solver.
For viscous flow problems near to steady-state, the action is \emph{convex} as a function of the ice velocity, i.e. its second derivative is positive-definite.
Convexity implies that the action functional has a unique minimizer and that, with an appropriate line search strategy, Newton's method will converge from any initial guess.
Minimizing a convex action functional is vastly more convenient numerically than solving a general nonlinear equation, although the two formulations are equivalent.

\subsubsection{Shallow ice approximation}

The shallow ice model can be derived from the Blatter-Pattyn approximation by assuming the ice flow is dominated by bed-parallel shear and that surface and basal slopes are small, i.e. $\partial u/\partial x \ll \partial u/\partial z$.
The result is a 2D system of equations for depth-averaged horizontal velocity.
The class in icepack that represents this physics model is called \texttt{ShallowIce}.
The terms in the action functional are:
\begin{align}
    \text{mass} & =\frac{1}{2}\int_\Omega u\cdot u\ud x\\\
    \text{gravity} & = \int_\Omega\frac{2A(\rho_I g)^n}{n+2} h^{n + 1}|\nabla s|^{n - 1}\nabla s\cdot u\ud x\\
    \text{penalty} & = \frac{1}{2}\int_\Omega \ell^2\nabla u\cdot \nabla u\ud x
\end{align}
and the action fuctional is
\begin{equation}
    J = \text{mass} + \text{gravity} + \text{penalty}.
\end{equation}
The default value of the length scale $\ell$ in the penalty term is defined as:
\begin{equation}
    \ell = 2\max\{\text{cell diameter}, 5h\}
\end{equation}
but users can adjust this to the value of their choice.
This penalty term smooths over numerical artifacts, especially near the ice margins and termini.
In these regions the shallow ice approximation is less applicable, so the error in solving a different set of equations is small compared to the inherent modeling error in using these equations in the first place.

The shallow ice approximation applies well in ice-sheet interiors.
For this reason, and because the equations are particularly simple to solve, this approximation has been a common choice for ice-sheet modeling \citep{kirchner2016shallow}.
Caution must be taken, however, because areas of the ice sheet that experience high vertical velocities (e.g., ice divides) or plug flow (e.g., ice streams) are not well represented by this approximation.

\subsubsection{Shallow stream and shelf approximations}

The shallow stream model can be derived from the Blatter-Pattyn approximation by assuming nearly plug flow, i.e. $\partial u/\partial z \ll \partial u/\partial x$.
The momentum equations can, again, be vertically integrated to obtain a 2D system of equations.
The class in icepack that represents this physics model is called \texttt{IceStream}.
The terms in the action functional are:
\begin{align}
    \text{viscosity} & = \frac{n}{n + 1}\int_\Omega hA^{-\frac{1}{n}}|\dot\varepsilon(u)|^{\frac{1}{n} + 1}\ud x \\
    \text{friction} & = \frac{m}{m + 1}\int_\Omega C|u|^{\frac{1}{m} + 1}\ud x \\
    \text{gravity} & = -\int_\Omega\rho_I gh\nabla s\cdot u\ud x \\
    \text{terminus} & = \frac{1}{2}\int_\Gamma(\rho_I gh^2 - \rho_Wgd^2)u\cdot \nu\ud\gamma
\end{align}
and the action functional is
\begin{equation}
    J = \text{viscosity} + \text{friction} - \text{gravity} - \text{terminus}.
\end{equation}
When the ice is floating, there are two simplifications: the friction coefficient $C$ is 0, and the surface elevation $s$ can be written in terms of the thickness $h$ as
\begin{equation}
    s = (1 - \rho_I / \rho_W)h.
\end{equation}
Additionally, the terminal stress term of the action disappears by applying integration by parts to the gravity term.
Since the action functional for ice shelves has fewer terms than for grounded ice streams, we have defined a separate \texttt{IceShelf} model class.
The ice shelf and ice stream models share common components, i.e. the viscosity and side wall stress.

Several studies have compared the shallow stream approximation to 3D models such as Blatter-Pattyn or full Stokes \citep{pattyn2013grounding}.
The most appreciable difference between lower- and higher-order models occurs near the glacier grounding line, where the full Stokes equations can represent bridging stresses \citep{van2013fundamentals}.
The lack of vertical strain rates in the ice viscosity in 2D models can also lead to different equilibrium grounding line positions under the same external forcing.
The shallow stream approximation is warranted for studying individual fast-flowing glaciers where the concern is more with studying processes and responses than with complete accuracy.


\subsubsection{Hybrid model} \label{sec:physics-hybrid-model}

The first-order model in icepack is described in the class \texttt{HybridModel}.
The shallow ice and shallow stream models follow directly from the variational principles described above.
The hybrid flow model, while also based on a variational principle, uses two more tricks: terrain-following coordinates and vertical spectral methods.
Each of these methods has appeared in the literature on glacier modeling before but never all in the same place for a 3D model.
\citet{langdon1978numerical} and \cite{bassis2010hamilton} used variational principles and vertical spectral methods, but these works considered only flowband and not 3D models.
\citet{kleiner2014numerical} used terrain-following coordinates for 3D glacier flow modeling, but they discretized the problem with finite difference methods in every direction and did not take into account the variational formulation of the diagnostic model.
\citet{jouvet2015multilayer} used vertical semi-discretization of the variational problem, but this model used a finite difference discretization in the vertical direction.

\paragraph{Terrain-following coordinates}

Rather than use the usual Cartesian coordinate system, the hybrid flow model uses terrain-following coordinates.
The terrain-following vertical coordinate $\zeta$ is
\begin{equation}
    \zeta = \frac{z - b}{h}
\end{equation}
where $b$ is the ice base.
We can then think of the computational domain as the Cartesian product of a 2D footprint domain $\Omega$ and the unit interval $[0, 1]$.

Both the bed elevation and thickness depend on $x$ and $y$.
As a result, the formula for the horizontal gradient of a field in terrain-following coordinates includes an additional geometric correction factor.
Letting $\nabla_z$ and $\nabla_\zeta$ denote the horizontal gradient with respectively $z$ and $\zeta$ held constant, the chain rule gives us that
\begin{equation}
    \nabla_zq = \nabla_\zeta q + \frac{\partial q}{\partial\zeta}\nabla\zeta,
\end{equation}
where we can calculate the spatial gradient of $\zeta$ as
\begin{equation}
    \nabla\zeta = -h^{-1}\left\{(1 - \zeta)\nabla b + \zeta\nabla s\right\}.
\end{equation}
Likewise, the strain rate of a vector field can be expressed as
\begin{equation}
    \dot\varepsilon_z(u) = \dot\varepsilon_\zeta(u) + \frac{1}{2}\left(u \otimes\nabla\zeta + \nabla\zeta\otimes u\right)
    \label{eq:geometric-correction}
\end{equation}
where $\otimes$ is the tensor product of two vectors.

For the Stokes equations, this alternative coordinate system also helps avoid the problem of how to enforce the condition $u\cdot \nu = -\dot a_b$ at the ice base, where $\nu$ is the unit outward normal vector and $\dot a_b$ is the basal mass balance.
This boundary condition is difficult to impose exactly because the unit outward normal vector $\nu$ is defined on mesh faces while the velocity is defined at mesh vertices.
Elmer/Ice uses an ad-hoc procedure to define the unit normal vectors at mesh nodes \citep{gagliardini2013capabilities}.
This procedure is nearly always effective in practice.
But with a transformation to terrain-following coordinates, we can set the terrain-following vertical velocity $\omega$ to be $-\dot a_b/h$ at the ice base to impose this boundary condition with no additional intervention.

We also argue that answers expressed in terrain-following coordinates are more intuitive in some respects than in Cartesian coordinates.
At the bed of a grounded glacier, the vertical velocity in Cartesian coordinates is
\begin{equation}
    w = -\dot a_b + u\cdot\nabla b.
\end{equation}
Knowing that a model gives a vertical velocity at the base of a glacier of, say, 10 cm/year, the modeler needs to also know the bed slope and sliding velocity.
In other words, it is not immediately clear whether the vertical velocity is a result of basal mass balance or of geometry without additional information.
By contrast, the vertical velocity $\omega$ in terrain-following coordinates evaluated at $\zeta = 0$ is completely determined by basal mass balance and ice thickness.


\paragraph{Spectral discretization}

Terrain-following coordinates open up several choices for how to describe the vertical variation of the velocity field.
In Elmer/Ice, for example, the user can extend the finite element discretization into a number of vertical layers.
The number of vertical layers is a user-tuneable parameter, depending on the desired resolution along this axis \citep{gagliardini2013capabilities}.

The horizontal velocity for many realistic flows is very smooth as a function of depth and this suggests a different approach.
For example, under the plug flow approximation, the horizontal velocity is constant with depth.
Under the shallow ice approximation, the horizontal velocity varies with depth as $1 - (1 - \zeta)^{n + 1}$ where $n = 3$ is the Glen flow law exponent.
This extra information about our solution suggests a modal rather than a nodal discretization strategy.

Rather than divide the spatial domain into many vertical layers, we can instead use only one vertical layer and increase the polynomial degree in the vertical direction to obtain higher resolution.
This type of basis, in which different shape functions are used in different dimensions, is called a \emph{tensor product} element.
Given a set of finite element basis functions $\{\phi_k(x, y)\}$ defined on the 2D domain $\Omega$ and a set of basis functions $\{\psi_l(\zeta)\}$ defined on the unit interval $[0, 1]$, the tensor product finite element basis $\{\Phi_{kl}\}$ on the extruded domain is defined as
\begin{equation}
    \Phi_{kl}(x, y, \zeta) = \phi_k(x, y)\psi_l(\zeta).
\end{equation}
For example, we can use piecewise linear or quadratic elements on triangles and use quintic or higher degree polynomials in the vertical.
Rather than use the usual Lagrange interpolating polynomial basis in the vertical dimension, we can instead use the Legendre polynomial basis.
The Legendre polynomials are mutually orthogonal and this choice makes the mass matrix block-diagonal.

The combination of using extruded meshes and tensor product elements in the vertical direction is referred to as \emph{semi-discretization}.
This approach can be thought of merely as a way to discretize a PDE that has special structure.
Alternatively, we can view vertical semi-discretization as defining a family of models indexed by the number of vertical basis functions.
The order-$d$ model defines a coupled system of PDEs for $d$ vector fields.
Each vector field represents one mode of vertical variability, similar to the distinction between barotropic and baroclinic modes in atmospheric physics and oceanography.
The system is then discretized in the horizontal and solved numerically.
In any case, the code is the same regardless of how one views the underlying mathematics.

The user then has to decide how many vertical modes are enough.
Using only degree 0 is exactly equivalent to the shallow stream approximation and we use this fact as a ``smoke test'' for the hybrid model.
The degree 2 model is the most minimalistic model that still exhibits vertical shear and can satisfy the zero-stress boundary condition at the ice surface.
Going to higher degree gives a more accurate approximation at the expense of greater computational effort.

\subsection{Substituting model components} \label{sec:physics-substitution}

Many aspects of glacier physics are not completely understood.
For example, the most common description of basal friction assumes that glacier sliding occurs through regelation, in which case the basal shear stress can be written
\begin{equation}
    \tau_b = -C|u|^{\frac{1}{m} - 1}u
    \label{eq:weertman-sliding}
\end{equation}
with $m = 3$ \citep{weertman1957sliding}.
Many authors have argued that, in fast-flowing regions of the ice sheet, glacier sliding occurs instead by plastic deformation within the subglacial sediments \citep{tulaczyk2000basal}.
For plastic sliding, the shear stress is dependent on the yield strength of the subglacial sediments and not on the sliding speed, in which case $m = \infty$ would be most appropriate.
Finally, the Schoof sliding law aims to reconcile the two modes of sliding \citep{schoof2005effect}.
Below a critical sliding speed, the shear stress is aymptotic to $|u|^{1/m}$ as in the Weertman sliding law, but above the critical speed the shear stress is independent of the sliding speed.

The Weertman and plastic sliding laws possess the same functional form but differ only in the value of a single scalar parameter $m$.
The Schoof sliding law, on the other hand, has a totally different functional dependence on the velocity.
Several authors, including Schoof, have proposed that the basal shear stress is also a function of the effective pressure $N = \rho gh - p_w$ within the subglacial hydrological system \citep{budd1979empirical, schoof2005effect}.
Implementing these more sophisticated mathematical models would require adding an extra argument to the procedure for solving the diagnostic equation.

One of our goals with icepack is to facilitate experimentation with the model physics, even for novice users.
Of the programming languages that are commonly used for scientific computing, only Python and possibly Julia would meet these needs.
To support use cases like implementing the Schoof sliding law, it must be possible to completely alter the functional form of a given model physics component.
For uses cases like explicitly adding the dependence of basal shear stress on hydrology, it must also be possible to add entirely new fields to a given model physics component.
In programming terms, this amounts to changing the number of arguments to the function that calculates basal shear stress.
For a library developed in C or Fortran, the user would then also have to change the signature of the diagnostic solve function, which is undesirable.
In C++, one could avoid changing the signature of the diagnostic solve routine by (1) using variadic templates, (2) wrapping the inputs in a class, or (3) passing all arguments in a dictionary.
Using variadic templates or wrapping the inputs in a class would require users to know more about generic or object-oriented programming than a novice might.
Using a dictionary data structure to pass arguments is relatively easier but would be more idiomatic in Python than in C++.

In icepack, users can substitute any diagnostic model component for the parameterization of their choosing, including adding new fields.
From the user's perspective, substituting model physics components does not require any advanced language features beyond keyword arguments.
To understand how this is possible, we'll briefly describe the path that the input fields take through the program.
\begin{enumerate}
    \item The user passes all arguments to the diagnostic solve procedure by keyword, essentially in a dictionary mapping names to fields.
    \item The diagnostic solve procedure creates a symbolic representation of the action functional by summing up several terms, like the viscosity, basal friction, etc.
        Calculating these terms is delegated to specialized procedures for each term.
        Each term procedure gets the entire collection of fields.
    \item The routine that calculates the terms of the action selects which fields it actually needs from the argument dictionary, and then creates the symbolic representation of that term.
    \item Finally, once the symbolic representation of the action functional has been created, all the responsibility passes to the nonlinear solver.
\end{enumerate}
To substitute different model components, the user intervenes at step 3.
Each model object -- shallow ice, shallow stream, etc. -- is initialized with a default set of routines to calculate the terms of that model's action functional.
The user can replace these default routines with one of their own choosing by passing the function of their choice when that model object is initialized.

In step 3, any fields that were unnecessary for calculating a given component are ignored.
For example, the gravitational driving power routine will pull out the velocity, thickness, and surface elevation.
It will have access to other fields, for example the ice fluidity.
These extra arguments are ignored.

In adopting this approach, we are restricted to using keyword arguments instead of positional arguments.
We argue that employing only keyword arguments is a strength rather than a weakness because it enhances readability and comprehensibility for the particular use case of calling a physics solver.
The user only needs to know the argument names, which are chosen to agree with the English name most commonly used in the literature -- ``friction'', ``rheology'', ``velocity'', etc.
The order of the arguments is arbitrary and immaterial.
The preference for argument passing by name is specific to this use case, however, and is not universal.

One key limitation of our approach is that, while users can change what goes into one or more terms of the action functional, they cannot add or remove terms.
This case would call for writing a new diagnostic model.

\subsection{Heat transport} \label{sec:heat-transport}

We implemented the enthalpy transport model described in \citet{aschwanden2012enthalpy}.
The enthalpy describes the heat content of the material in a way that incorporates both temperature and latent heat stored in meltwater.
The temperature and meltwater fraction can be uniquely calculated at any point from the value of the enthalpy, so nothing is sacrificed in describing heat content one way or the other.
Using the enthalpy has the advantage of circumventing many of the difficulties associated with tracking the interface between cold and temperate ice.
Our implementation of the model uses all of the simplifying assumptions described in \citet{aschwanden2012enthalpy}, for example that horizontal diffusion is negligible and that heat capacity and conductivity are not temperature-dependent within each phase.

The fluidity factor $A$ in Glen's law is roughly a known function of both temperature and melt fraction and we have included this function in the package.
Having some description of heat transport is thus necessary for describing realistic glacier flows, but it is not sufficient by itself.
For one, while the dependence of fluidity on temperature is known fairly well from laboratory experiments, the dependence on melt fraction is known with much less certainty.
It is likely that users of this module will want to substitute in their own parameterization for melt fraction dependence.
Second, other processes such as damage, fabric development, and impurities can affect the fluidity as well.
For these reasons, the diagnostic model takes in the fluidity as an argument and users must calculate the fluidity field themselves, either using the default parameterization that icepack supplies or one of their own.
Our general design principle is that icepack will solve differential equations for the various prognostic fields but it's up to users to decide how these fields are coupled.

We have not implemented a model for the surface or englacial transport of meltwater, although it would be possible to include this process.
Instead, we rely on an external scheme to act as a sink of enthalpy for meltwater fraction values above some user-defined critical value, which defaults to 1\%.

\subsection{Damage transport} \label{sec:damage-transport}

Other physical fields besides temperature can influence ice fluidity.
At large spatial scales (> 5 km), crevasse fields affect ice flow by reducing the lateral area over which stress can be transmitted.
Modeling individual fractures is not computationally feasible for large-scale simulations.
Instead, we have implemented the phenomenological model described in \citet{albrecht2014fracture}, which is based on the theory of continuum damage mechanics.
This model is defined in the class \texttt{DamageTransport}.
Prognostic damage models can be broken down into three parts: (1) evolve the damage field based on the membrane stress of the glacier, (2) advect the damage field with flow, and (3) feed the damage field back into the fluidity of the glacier.
Changes in fluidity in turn affect the membrane stress; the coupling between bulk damage and ice flow goes both ways.
The model from \citet{albrecht2014fracture} adds sources of damage where the membrane stress exceeds a critical value and sinks of damage when the principal strain rate is less than a critical value.
These kinds of simplified models ignore complications such as inertial or 3D effects.
They are intended more to capture some important features of the real physical system ecnomically than to describe it exactly.


\section{Data assimilation} \label{sec:data-assimilation}

Icepack includes a set of routines for estimating the basal friction or rheology coefficients from observational data.
The class \texttt{InverseProblem} represents the specification of an inverse problem, which requires:
\begin{itemize}
    \item the model object and the method that solves the diagnostic equation,
    \item the objective and regularization functionals,
    \item the observed field and the name of the argument to the diagnostic solver,
    \item an initial guess for the field to be estimated and the name of the argument to the diagnostic solver,
    \item extra data passed to the diagnostic solver such as boundary conditions.
\end{itemize}
This class currently assumes that the observed state is always the ice velocity.
In principle the same design would suffice for more complicated inverse problems and this is an area of active development.

The inverse problem class is flexible enough to account for users defining their own parameterization for the rheology or friction coefficient as described in \S\ref{sec:physics-substitution}.
This flexibility with respect to parameterization is not just convenient but essential for common data assimilation workflows.
Nearly all studies in the literature introduce a parameterization of the field to be estimated in terms of some auxiliary field in order to guarantee positivity \citep{macayeal1992basal, joughin2009basal}.
For example, one could define the friction coefficient $C$ in terms of an auxiliary variable $\beta$ as $C = \beta^2$ to guarantee positivity.
One could also just as easily use $C \propto \exp(\beta)$.
The data assimilation routines in icepack can work the same for any parameterization of the physics because Firedrake provides a rich set of routines for symbolically calculating functional derivatives.
The inverse problem class only needs to know which functional needs to be differentiated with respect to which field.

The \texttt{InverseSolver} class is responsible for actually solving the inverse problem.
This class will be described further in section \S\ref{sec:numerics-inverse-solvers}.


\section{Numerics}

In the previous sections we described \emph{what} problems icepack can solve, i.e. various physics models and data assimilation problems.
In this section, we'll describe \emph{how} these problems are solved.
This separation between the two questions parallels the broader design of the software package.

The key classes that users interact with are flow models and solvers.
The role of the model classes is to describe what problem is being solved.
These classes describe the diagnostic model by taking in the input fields -- ice velocity, thickness, surface elevation, etc. -- and returning a symbolic representation of the action functional.
There are several model classes, one for each set of physics equations: \texttt{ShallowIce}, \texttt{IceShelf}, \texttt{IceStream}, \texttt{HybridModel}.
The model classes do not dictate how that problem should be solved numerically; this is the realm of a separate class called \texttt{FlowSolver}.
This flow solver class has methods for computing the solutions of the diagnostic and prognostic equations and works the same regardless of which model is being solved.
The diagnostic solve method amounts to invoking an external Newton solve procedure on the symbolic action functional that the model object creates.
The Newton solver itself is completely standard but the convergence criterion is not and will be discussed in section \S\ref{sec:convergence-criteria}.
Finally the flow solver has a method to update the ice thickness from the current value, the ice velocity, and the mass balance rates.
The prognostic solver will be discussed in section \S\ref{sec:prognostic-model}.

The Unified Form Language for specifying weak forms of PDEs contains all of the primitives necessary to express individual terms of the action functional.
These primitives consist of the basic vector calculus operators like the gradient of a field, tensor calculus operations like taking the dot product of two vectors or tensors, scalar functions like the square root or exponential, and symbolic integration over the mesh or its boundary.
For example, the strain rate for a given velocity field $u$ can be written as \texttt{sym(grad(u))}, where the function \texttt{grad} represents the symbolic gradient of a field and \texttt{sym} represents the symmetrization of a rank-2 tensor.


\subsection{Advective transport} \label{sec:prognostic-model}

The simplest explicit timestepping schemes are unstable with continuous Galerkin finite elements.
To solve the advection equation equation, other packages use the streamlined upwind Petrov-Galerkin (SUPG) method for the timestepping scheme \citep{brinkerhoff2013data, larour2012continental}.
The SUPG method with an explicit time discretization is conditionally stable \citep{donea2003finite}.
This scheme introduces a tuneable stabilization parameter, so in the interest of simplicity we instead default to the implicit Euler scheme.
The implicit Euler scheme requires solving a non-symmetric linear system, but the computational cost comes with the advantage of unconditional stability.

Practicing glaciologists who have not studied numerical PDE may be unfamiliar with the Courant-Friedrichs-Lewy condition.
The use of an unconditionally stable scheme guarantees that they will get an answer, rather than a runtime error, should they try to use a large timestep.
The extra cost of using an implicit time discretization for the prognostic equation is dwarfed by the cost of the diagnostic solve in any case.
Advanced users who are interested in maximizing performance can subclass the solver to implement a faster explicit scheme.

The implicit Euler scheme tends to diffuse out sharp discontinuities that may be present in the true solution \citep{donea2003finite}.
Since the ice thickness does not possess shockwaves or propagating discontinuities this error mode is tolerable.
The coupling of ice thickness to velocity makes the whole system more resemble a parabolic problem than a hyperbolic one, and under the shallow ice approximation the system is truly parabolic.

Other problems in glaciology have more of a hyperbolic character.
For example, the thresholding behavior of the source terms for the damage model (see \S\ref{sec:damage-transport}) can create sharp discontinuities.
The implicit Euler scheme would obscure this important feature.
For the damage solver, we have instead used a strong stability-preserving Runge-Kutta method in time and a discontinuous Galerkin basis in space to best capture these sharp interfaces \citep{shu1988efficient}.


\subsection{Convex optimization}

The action functional for each diagnostic model is convex, i.e. the second derivative is strictly positive-definite.
From a theoretical persepctive, convexity guarantees that the problem has a unique solution.
This property is also especially advantageous for implementing numerical solvers.
We use a damped Newton method to solve the diagnostic equations.
Starting from a guess $u_k$ for the velocity, the \emph{search direction} $v_k$ is the unique solution of the linear system
\begin{equation}
    \ud^2J(u_k)\cdot v_k = -\ud J(u_k).
    \label{eq:newton-search-direction}
\end{equation}
The next approximation for the velocity minimizes $J$ along the search direction $v_k$ starting from $u_k$, i.e.
\begin{align}
    u_{k + 1} & = u_k + \alpha_k\cdot v_k, \nonumber\\
    \alpha_k & = \text{argmin}_\alpha \hspace{2pt}J(u_k + \alpha v_k).
\end{align}
For an initial guess sufficiently close to the exact solution, the undamped Newton method ($\alpha_k = 1$ at every step) converges quadratically.
The line search step ensures that the method can converge even from a poor initial guess, provided that the line search method satisfies the Armijo-Wolfe criteria \citep{nocedal2006numerical}.

For a convex problem, $\ud^2J$ is a symmetric and positive-definite matrix.
This has two advantages.
First, the search direction is always a descent direction for $J$.
For non-convex problems this is not always the case and some adaptation strategy must be employed in the vicinity of saddle points.
Second, symmetry and positivity enable the use of specialized linear solvers, such as the Cholesky decomposition or the conjugate gradient algorithm, that are superior to their more general counterparts in many respects.

Other software packages that treat diagnostic models as nonlinear systems of equations tend to rely on ad-hoc procedures for initializing the numerical solution process.
For example, without a damping procedure in Newton's method, the iteration can prove unstable if initialized far away from the true solution.
Some packages combat this problem by using a few iterations of the more robust but slower Picard method first \citep{gagliardini2013capabilities}.
While this approach can be effective it requires tuning the number of Picard iterations and there is no guarantee that an adequate amount for one problem will work well on another problem.
This issue rarely appears on realistic input data.
When solving inverse problems, however, the intermediate guesses for the inferred field can be wildly unrealistic before converging.
A forward model solver that is not sufficiently robust can crash in these extreme scenarios.
By contrast, a damped Newton procedure using a line search that satisfies the Armijo-Wolfe criteria is guaranteed to converge on non-degenerate, if unrealistic, input data.


\subsection{Convergence metrics} \label{sec:convergence-criteria}

Several works in the literature have weighed the relative merits of different iterative methods for solving the nonlinear diagnostic equation, for example \citet{perego2012parallel}.
Few have considered the problem of when to stop iterating.
The most common stopping criteria are when (1) the 2-norm of the residual is sufficiently small or (2) the relative change in the iterates is sufficiently small.
Each of these approaches has problems.
The residual norm depends on the discretization and does not weight all degrees of freedom proportionally, e.g. vertex and edge degrees of freedom in higher-order finite element methods.
The relative change criterion, on the other hand, can suggest convergence when in fact the method has stagnated.

A convergence criterion that works equally well independent of the mesh, finite element discretization, and the quality of the initial guess can be defined based on the idea of the \emph{Newton decrement} \citep{nocedal2006numerical}.
Since the second derivative operator $\ud^2J(u_k)$ is positive-definite, the Newton search direction $v_k$ computed from equation \eqref{eq:newton-search-direction} is a descent direction for $J$:
\begin{equation}
    \ud J(u_k)\cdot v_k < 0.
\end{equation}
The absolute value of the quantity in the last equation is defined as the Newton decrement.
For $u_k$ sufficiently close to the true solution $u$, the Newton decrement roughly tells us how much we can expect the action to decrease:
\begin{equation}
    J(u_k) - J(u) \approx \frac{1}{2}|\ud J(u_k)\cdot v_k|.
\end{equation}
We can then use the Newton decrement to decide when to stop the iteration.

As shown in equation \eqref{action-functional}, the action for most models has units of power and is the sum of dissipation due to viscosity, friction, gravitational driving, and ocean back-pressure at the terminus.
The viscous and frictional terms are convex, positive functions of the velocity.
The gravitational and terminus stress terms are linear in the velocity and can be of either sign.
If we define the \emph{scale functional}
\begin{equation}
    K(u) = \text{viscous dissipation} + \text{frictional dissipation}
\end{equation}
as only the positive parts of the action, then the convergence criterion
\begin{equation}
    |\ud J(u_k)\cdot v_k| < \epsilon K(u_k)
\end{equation}
is independent of the discretization.
The intuition behind this criterion is that the iteration is halted when the expected decrease in the action functional is much smaller than the positive part of the action itself.

We have found empirically that, with this criterion and the Newton solver implementation in icepack, the iteration usually converges to machine precision in around 8 steps.
The iteration count can reach as high as 20 for exceptionally bad initial guesses for the velocity or with unphysical fluidity or friction values.
We also observe the expected doubling of the number of accurate digits in the value of the action once the velocity guesses are within the convergence basin of the true solution.
Other convergence criteria, such as using relative change in the velocity guesses, can terminate prematurely when the initial guess is very far outside the quadratic convergence basin.

The numerical solvers in icepack have been designed so that users who are not familiar with numerical optimization need not be confronted with a possibly bewildering array of algorithmic parameters.
Consequently, sensible defaults have been chosen for the Armijo and Wolfe criteria \citep{nocedal2006numerical}, and the tolerance for the line search is chosen based on that of the outer-level Newton iteration.
The Newton search direction is calculated using a direct factorization solver rather than, say, the conjugate gradient algorithm, as the use of another iterative method would introduce yet another algorithmic parameter.
Advanced users who are interested in performance optimization can change these algorithmic parameters by passing extra arguments to the solve procedure.


\subsection{Inverse solvers} \label{sec:numerics-inverse-solvers}

The \texttt{InverseProblem} class describes what problem is being solved, while the \texttt{InverseSolver} class is responsible for carrying out the numerical optimization.
There are three inverse solvers in icepack: a simple gradient descent solver, a quasi-Newton solver based on the BFGS approximation to the Hessian, and a Gauss-Newton solver.
All of these classes are based around the general idea of first computing a search direction and then performing a line search.
They differ in how the search direction is computed.

The gradient descent solver uses the search direction
\begin{equation}
    \phi_k = -M^{-1}\ud J(\theta_k)
\end{equation}
where $M$ is the finite element mass matrix.
Gradient descent is a popular choice because the objective functional is always decreasing along this search direction.
However, the search direction can be poorly scaled to the physical dimensions of the problem at hand.
This method can be very expensive and brittle in the initial iterations and often takes many steps to converge.

The BFGS method uses the past $m$ iterations of the algorithm to compute a low-rank approximation to the inverse of the objective functional's Hessian matrix; see \citet{nocedal2006numerical} for a more in-depth discussion.
The BFGS method converges faster than gradient descent.
However, it suffers from many of the same brittleness issues in the initial iterations before it has built up enough history to approximate the Hessian inverse.

Finally, the Gauss-Newton solver defines an approximation to the ``first-order'' part of the objective functional Hessian.
Each iteration of Gauss-Newton is more expensive than that of BFGS or gradient descent because it requires the solution of a more complex linear system than just the mass matrix.
The Gauss-Newton method converges fastest by far in virtually every test case we have found, in some instances by up to factor of 50.

The derivative of the objective functional with respect to the unknown parameter is calculated using the symbolic differentiation features of Firedrake.
The user does not need to provide any routines for the derivatives, only the symbolic form of the error metric and the regularization functional.
The model object is responsible for providing the symbolic form of the action functional.


\subsection{Hybrid model}

The hybrid flow uses several features that are only available in Firedrake to better exploit the special structure of the problem.
Implementing this model also required some mathematical sleight-of-hand related to the terminus boundary condition that has not appeared in the literature before.
Additionally, the hierarchical structure of spectral basis functions presents an opportunity for developing fast algorithms.
In all other respects the implementation of the hybrid flow model using convex optimization follows the techniques described above.

\subsubsection{Discretization}

In order to use terrain-following coordinates, the hybrid model assumes that the geometry of the domain is an extruded mesh, where a 2D footprint mesh is lifted into 3D.
Firedrake includes support for creating extruded meshes by calling the function \texttt{ExtrudedMesh} on the 2D footprint \citep{bercea2016structure, mcrae2016automated}.
The cells of an extruded mesh are triangular prisms instead of the more common tetrahedra used for general 3D meshes.
Not every 3D domain can be described by extruding a 2D domain, but the geometry of most glacier flow problems can.

The geometric correction factor in equation \eqref{eq:geometric-correction} for gradients in terrain-following coordinates can easily be represented in UFL.
By defining a wrapper around the UFL \texttt{grad} function, the code to define the action functional in terrain-following coordinates is only slightly more complex than in Cartesian coordinates.

For problems defined on extruded geometries, Firedrake includes support for tensor product elements, which includes using different bases in the horizontal and vertical directions \citep{mcrae2016automated}.
Tensor product elements are defined in Firedrake by passing the extra keyword arguments \texttt{vfamily}, \texttt{vdegree} to the constructor for a function space.
In our case, we used the usual continuous Galerkin basis in the horizontal and Gauss-Legendre elements in the vertical.
To select the Legendre polynomial basis, the user passes the keyword argument \texttt{vfamily=`Gauss-Legendre'} or \texttt{`GL'} for short to the constructor for the function space.

Extruded meshes and tensor product elements are available in Firedrake but not in FEniCS.
Other general-purpose finite element modeling packages that support tensor product elements include deal.II and nektar++ \citep{bangerth2007deal, cantwell2015nektar++}.
Like most other packages in this domain, deal.II and nektar++ are written in C++, whereas our goal for icepack was to have both the core and the user interface in Python.

\subsubsection{Ocean boundary condition}

Our approach for implementing a hybrid flow model works completely seamlessly but for one important detail.
The backpressure from ocean water at the calving front of a marine-terminating glacier is not a smooth function of depth.
The pressure is 0 above the water line and linearly increasing below it:
\begin{equation}
    \text{backpressure power} = \int_\Gamma\int_0^1 \rho_Wgh(\zeta_{\text{sl}} - \zeta)_+\ud\zeta\ud\gamma,
    \label{backpressure}
\end{equation}
where $\zeta_{\text{sl}}$ denotes the relative depth to the water line and the subscript $+$ denotes the positive part of a real number.
Were we to use the standard asssembly procedure in Firedrake to evaluate this integral, we would get an inaccurate result due to an insufficient number of integration points.
The resulting velocity solutions are then wildly inaccurate due to the mis-specification of the Neumann boundary condition.
A blunt solution to this problem would be to pass an extra argument to the Firedrake form compiler that specifies a much greater integration accuracy in the vertical for this term.
This fix reduces the errors in the velocities, but it does not eliminate them completely and it incurs a large computational cost.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/legendre/pressure.png}
    \caption{The normalized ocean pressure ($p_w / \rho_Wg$) and Legendre polynomial approximations of several degrees (left), and the residuals of the approximation (right).
    For this particular example, the waterline is at $\zeta = 1/3$.
    The moments of each of the residuals up to the approximation degree are all zero.}
    \label{fig:legendre}
\end{figure}

We instead implemented a routine that symbolically calculates the Legendre polynomial expansion of the function $(\zeta_{\text{sl}} - \zeta)_+$ with respect to the parameter $\zeta_{\text{sl}}$ using the package SymPy \citep{sympy}.
The symbolic variables for $\zeta$ and $\zeta_{\text{sl}}$ used in the SymPy representation of the polynomial expansion are then substituted for equivalent symbolic variables in Firedrake/UFL using the SymPy object's \texttt{subs} method.
The Legendre polynomial approximation to this function only converges linearly as the number of coefficients is increased, since the the function is continuous but not smooth, and the approximation exhibits noticeable ringing artifacts at high degree.
While the approximation itself is not very accurate, the calculated value of the integral in equation \eqref{backpressure} is exact because of the orthogonality property of Legendre polynomials.
Stated another way, the residuals in the approximation are large, but they integrate to 0 when multiplied by any Legendre polynomial up to the number of vertical modes.
An example of the pressure approximations using linear, quadratic, and cubic Legendre polynomials are shown in figure \ref{fig:legendre}.

The exact symbolic integration approach is both faster and more accurate than using a large number of quadrature points.
The same technique could be used to exactly calculate the ocean backpressure for any model, say the full Stokes equations, using terrain-following coordinates together with a Legendre polynomial expansion in the vertical.


\section{Demonstrations}

\subsection{MISMIP+}

As a first test case for icepack, we ran the first experiment from the Marine Ice Sheet Model Intercomparison Project version 3 (MISMIP+).
The parameters and geometry for this experiment can be found in \citet{asay2016experimental}.
The MISMIP+ experiment has three phases.
First, the model must find a steady state marine ice sheet with a fixed accumulation rate and no submarine melting.
Next, submarine melting with a given depth-dependent parameterization is applied for 100 years.
The increased melt thins the ice ice shelf and initiates a retreat of the glacier grounding line.
Finally, submarine melting is turned off for at least 100 years, optionally longer.
The grounding line then readvances, but not as far as its original position.

The original intercomparison project specified that participants could use the Weertman sliding law (equation \eqref{eq:weertman-sliding}) as well as two other sliding laws that transition to a more plastic rheology at high sliding speeds.
The first alternative sliding law consists of Weertman sliding until the stress reaches a critical value, at which point the constitutive relation transitions to perfect plasticity.
The second alternative is the Schoof sliding law \citep{schoof2005effect}:
\begin{equation}
    \tau_b = -\frac{C|u|^{1/m}\cdot \tau_c}{(C^m|u| + \tau_c^m)^{1/m}}\frac{u}{|u|},
    \label{eq:schoof-sliding}
\end{equation}
where the critical stress $\tau_c$ is a certain specified fraction of the water pressure in the subglacial hydrological system.
Sliding laws in icepack are not expressed directly, but rather as the the derivative of an action functional.
To implement the Schoof sliding law we need to know the antiderivative of equation \eqref{eq:schoof-sliding}.
Using a computer algebra system, we found that the antiderivative of this expression in terms of hypergeometric functions.
The Unified Form Language has several transcendental functions (sine, cosine, exponential, etc.), but it does not currently support hypergeometric functions.
Instead, we implemented a sliding relation that exhibits the important features of the Schoof law, i.e. it behaves like an $m = 3$ power law at low sliding speeds and $m = \infty$ at high sliding speeds, but which is more tractable algebraically.
Knowing the critical stress $\tau_c$ and the friction coefficient $C$, which has units of stress $\times$ speed${}^{-1/m}$, we can define a \emph{critical speed} $u_c$ as
\begin{equation}
    u_c = C^{-m}\tau_c^m.
\end{equation}
The power dissipation density for the Schoof-type sliding law that we use is
\begin{equation}
    P = \tau_c\left\{\left(u_c^{\frac{1}{m} + 1} + |u|^{\frac{1}{m} + 1}\right)^{\frac{m}{m + 1}} - u_c\right\}
    \label{eq:power-dissipation-modified-schoof-sliding}
\end{equation}
Figure \ref{fig:sliding-laws} shows a comparison of the original Schoof sliding law and the sliding law that arises as the derivative of the functional in equation \eqref{eq:power-dissipation-modified-schoof-sliding}.
The two have the same asymptotic behavior when the speed is much smaller or much larger than the critical speed; they differ in a relatively small range around the critical speed.
The relative difference in basal shear stress between the two sliding laws is less than 10\% throughout the entire range.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/sliding/sliding-law.png}
    \caption{The Weertman, Schoof, and modified Schoof sliding law of equation \eqref{eq:power-dissipation-modified-schoof-sliding}.
    The critical speed and shear stress are $u_c = 250$ m/year and $\tau_c = 100$ kPa.}
    \label{fig:sliding-laws}
\end{figure}

The source code implementing both of these approaches is contained in the supplementary material.
To change the sliding law, users only need to pass one function or the other to the model object at initialization.
Users do not need to implement a subclass that overrides some parent method.
This approach would be idiomatic in C++, but it requires some facility with object-oriented programming that a non-expert might lack.

Figure \ref{fig:mismip} shows the outcome of the MISMIP+ experiment performed using icepack.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/mismip/steady-state.png}
    \caption{The steady state thickness and velocity of the MISMIP+ experimental setup with the Weertman sliding law.}
    \label{fig:mismip}
\end{figure}

Using variational principles to express all constitutive laws is less flexible than specifying the sliding law directly and this is a distinct disadvantage.
We were able to implement a sliding law that exhibits many of the characteristics of the Schoof sliding law.
\citet{asay2016experimental} also suggest using a sliding law that transitions sharply to exact plasticity above the critical speed.
Expressing this sliding law in UFL requires a conditional in the velocity and is thus no longer differentiable.
This lack of differentiability makes the forward solver crash.
The numerical advantages of using variational principles are so great, however, that we view this tradeoff as acceptable.


\subsection{Synthetic ice sheet}

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/ice-sheet/ice-sheet.png}
    \caption{Synthetic ice sheet simulation. (a) The bed elevation profile consists of a ring of mountains with valleys of varying depth surrounding a flat plateau where the ice sheet is initialized.
    The black square outlines the domain of subplot (b) which shows the velocity of the ice as it passes through the southernmost mountain pass, with contours of the bed elevation shown in greyscale.}
    \label{fig:ice-sheet}
\end{figure}

As a demonstration of the shallow ice approximation model, we ran an experiment inspired by \cite{kessler2008fjord}.
In this work, the authors coupled an ice flow model to simple models for bed-erosion, calving, and glacial isostatic adjustment (GIA) to investigate the formation of deep fjords that are characteristic of coastlines on Baffin Island, Greenland, and British Columbia, among others.
We emulated their domain and bedrock geometry -- a plateau surrounded by a ridge punctuated by four valleys -- without also simulating erosion or GIA.
These effects will be the subject of future work.

Figure \ref{fig:ice-sheet} shows the results of this computational experiment.
We initialized the experiment with a simple but unrealistic ice thickness.
We then evolved the ice sheet without climate forcing for 500 years.
The ice sheet relaxes very rapidly in the first 200 years, but after this changes are much slower as ice must be funneled through one of the four narrow valleys.
The resulting velocity pattern is similar to that of \citet{kessler2008fjord}, with the highest velocities where ice flows out from the valleys.
In and upstream of the valleys, the surface is drawn down due to the elevated export of ice.

The diagnostic model used in this demonstration is cheap enough that it can be used to simulate ice sheets over several millenia in a matter of minutes on a desktop.
A key feature of icepack is the ability to choose between many different diagnostic models.
Users are free to decide what model works best for the spatial and temporal scales of their problem, how accurately they need to solve this problem to produce useful results, and what computational resources they are willing to devote.


\subsection{Synthetic ice shelf}

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/gibbous/damage.png}
    \caption{Results of ice shelf damage simulation: (a) ice velocity without damage, (b) change in ice speed with and without damage, (c) thickness, and (d) damage field.}
    \label{fig:damage}
\end{figure}

We simulated the evolution of a synthetic ice shelf towards steady state and coupled it with the damage transport model described in \S\ref{sec:damage-transport}.
The geometry of the ice shelf consists of the intersection of two circles, one with a larger radius and offset center, designed to roughly mimic the shape and size of real ice shelves.
The radius of the whole shelf is 200km.
Four ice streams flow into the shelf with varying speeds and a prescribed inflow thickness.
In the first phase of the experiment, the ice shelf is propagated to steady state without damage for 200 years.
After this time interval, the flux imbalance is less than 1\% of the influx.
In the second phase, damage transport is turned on and coupled to the ice velocity.
An interesting feature to observed in the approximate equilibrium damage field is that the highest values occur between the streams and not within them.
Additionally, the spacing between the streams changes as a result of adding damage.
The final ice thickness, velocity, strain rate, and damage are shown in figure \ref{fig:damage}.


\subsection{Larsen C Ice Shelf}

To demonstrate the inverse solver, we will estimate the rheology of the Larsen C Ice Shelf in the Antarctic Peninsula from observational data.
Several recent studies have focused on Larsen C because it may be unstable in the warmer climate of the coming decades.
From January to March of 2002, the neighboring Larsen B Ice Shelf disintegrated due to surface melt pond-induced fracture \citep{banwell2013breakup}.
This mechanism might also lead to the breakup of Larsen C in the future.
One of the key factors affecting the stability of ice shelves is the presence of marine ice -- seawater that freezes onto the base of an ice shelf -- in the suture zones where two flow units meet \citep{kulessa2014marine}.
Marine ice is warmer than meteoric ice and usually includes brine pockets, which are discernible in radio echo sounding measurements as the absence of reflection from the ice shelf base \citep{holland2009marine}.
This warmer and impurity-laden ice is more ductile and thus less prone to fracture than cold and brittle meteoric ice.
Ocean models predict that marine ice forms under Larsen C as well \citep{holland2009marine}.
By estimating the material rigidity of an ice shelf, we can constrain where marine ice may be forming.


\subsubsection{Data}

We used the InSAR phase-based ice velocity map from \citet{mouginot2019continent}.
This dataset has nominal errors over the Larsen Ice Shelf on the order 1 -- 7 meters per year.
We used the recently-released BedMachine map of the thickness of Antarctica \citep{morlighem2019deep}.
This data product improves on existing thickness maps for the continent by using the mass conservation law, together with measurements of the velocity, surface elevation, and surface mass balance, to improve thickness estimates where few measurements are available.

Existing work on glaciological inverse problems uses the mismatch between the computed and observed velocity fields as part of the objective functional.
The effect of thickness errors is studied largely through a posteriori validation \citep{joughin2004basal, larour2005rheology}.
Errors in thickness or surface slope can be large enough that it might be impossible to fit the velocity measurements to the degree that statistical theory predicts \citep{macayeal1995basal}.
The velocity measurements themselves might have significant outliers, in which case using the usual weighted sum of squared misfits as an error metric will give poor results.
For these reasons, some studies have explored alternative objective functionals \citep{morlighem2010spatial}.
We have opted to use the regularized $L^1$-type error metric
\begin{equation}
    E(u - u^o) = \int_\Omega\left(\sqrt{\frac{|u - u^o|^2}{\sigma^2} + \gamma^2} - \gamma\right)\ud x.
    \label{eq:l1-error-metric}
\end{equation}
This error metric approaches the usual weighted sum of squared errors as $\gamma \to \infty$, and approaches the sparsity-promoting $L^1$ error metric as $\gamma \to 0$.
For finite, positive values of $\gamma$ this error metric is robust to non-normality or a small fraction of outliers \citep{barron2019general}.


\subsubsection{Parameterization}

The rheology parameter of an ice shelf is strictly positive.
The optimization algorithm, however, can explore unphysical regions of parameter space without some a priori constraint on what values are reasonable.
Rather than try to solve an inequality-constrained problem, most studies in glaciology instead re-parameterize the problem in terms of some auxiliary field in such a way that the rheology is manifestly positive.
In this case we will use the parameterization
\begin{equation}
    A = A_0e^{\theta}
\end{equation}
and estimate $\theta$.
The inverse solver calculates the derivative of the objective functional symbolically and is thus agnostic to the particular parameterization.
The only information that the user needs to pass is the name of the arguments to the forward model representing the parameter and the observed field so that these can be passed by keyword.


\subsubsection{Results}

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/larsen/parameter.png}
    \caption{Left: Inferred fluidity parameter $\theta$.
    Lower values indicate more deformable ice.
    Right: stream plot of ice velocity computed from this fluidity parameter.}
    \label{fig:larsen}
\end{figure}

The inferred parameter field $\theta$ is shown in figure \ref{fig:larsen}.
The algorithm detects areas of much lower ice rigidity around highly damaged ice.
This feature is especially apparent around the large rift emanating from the Gipps Ice Rise, as well as the crevassed areas upstream.
We find other areas of low rigidity in the suture zones where two flow units converge and where marine ice tends to form, releasing heat to the ice shelf, exactly as observed in \citet{holland2009marine}.
Finally, the inferred rheology field reproduces features that have already been found in previous studies of Larsen C Ice Shelf \citep{khazendar2011acceleration}.

The final value of the model-data misfit \eqref{eq:l1-error-metric} matches the value we would expect if the velocity errors actually came from this probability distribution.
In a separate computational experiment, we used the older bedmap2 ice thickness map instead of BedMachine \citep{fretwell2013bedmap2}.
We were unable to achieve the same model-data misfit using bedmap2 at the same grid resolution with any regularization parameter.


\section{Usability}

One of the main goals for icepack is to create a tool that is accessible to researchers who might not be experts in scientific computing.
Previous work on numerical modeling of glacier flow has focused largely on technical details of the models themselves -- does a given solver converge with the accuracy expected from finite element theory, does it scale to large numbers of processors, can models accurately predict grounding line retreat, etc.
The human learning to use an unfamiliar software tool is largely absent from the discussion.
For graduate students or other researchers who are not experts in computational physics, the difficulty of learning to use a particular software package may be more of a rate-limiting factor than the speed or efficiency of that software.

The field of \emph{human-computer interaction} (HCI) asks how we can design software that is easiest to learn and use effectively.
In the following, we will describe some of the design choices in icepack and how they relate to what HCI researchers call the \emph{cognitive dimensions of notations}.
\citet{green1996usability} introduced this concept to assess the usability of visual programming languages, but the criteria they laid out in this paper have been used to analyze software systems across many disciplines.

\textbf{Consistency: After a user learns part of the software, can they guess the remaining parts?}
Each of the model objects in icepack is a class with a method ending in \texttt{solve} that takes in keyword arguments for the various input fields and options for things like boundary conditions.
Users already familiar with, say, the \texttt{IceStream} class can then use the \texttt{HeatTransport} class under the assumption that the input fields -- the current temperature $T$, ice velocity $u$, and basal melt rate $m$ -- are passed as keyword arguments with the same name as the fields themselves.
Consistency obviates the need for repeatedly consulting the documentation or examples once users are already familiar with the software.

\textbf{Progressive evaluation: How easily can users get feedback during their use of the software?}
Progressive evaluation is the main advantage of having a user interface in an interpreted programming language such as Python as opposed to a compiled language where programs can only run in batch mode.
In the early stages of the development process, any non-trivial simulation of a physical system exists as a prototype which may be non-functional or even broken.
The ability to manually step through a simulation and examine the entire state in an interpreter is critical to finding errors faster.
Icepack was designed to give fine-grained control over how simulations work in order to support this mode of debugging.
The API provides routines for solving the diagnostic and prognostic equations.
It is the user's responsibility for making the repeated calls to these routines, either in a loop or by manually iterating through one step at a time.
With this responsibility comes the freedom to add in arbitrary code.
This capability might be used to add sanity checks, such as printing minimum and maximum thickness or velocity values.
It can also be used to get feedback on how long the simulation will take, or to save results for later visualization.
Other packages support a more coarse-grained view where the user only specifies the start and end time of a simulation and has more limited options for inspecting the state of the running program.

Icepack makes extensive use of Jupyter notebooks as a form of executable documentation.
Jupyter notebooks are a document format that includes code and explanatory text with typeset mathematics that runs interactively in a web browser \citep{kluyver2016jupyter}.
The contents of a notebook can executed incrementally much like running code in the Python interpreter.
Most importantly, Jupyter notebooks can render and display visualizations on the fly.
This enables a workflow where plotting all intermediate results serves for sanity-checking an experimental simulation.

\textbf{Abstraction gradient: What are the levels of abstraction exposed by the library?
Can irrelevant details be hidden?}
The API for icepack has been designed so that the users only need to decide what problem to solve and not how to solve it.
Where a choice does concern more the ``how'' than the ``what'', we use a sensible default that biases for correctness rather than speed.
For example, the Newton solver uses a direct factorization method to solve the linear system for the search direction because factorization requires no tuning whereas iterative methods do.
A user interested in achieving greater runtime performance can pass additional keyword arguments instead specifying, say, the preconditioned conjugate gradient method.
This choice is of interest mostly to advanced users so we keep the linear solver algorithm as a default argument.
In so doing, we avoid confronting novice users with options that they might not understand.

Advanced users who do wish to tune solver performance for large simulations will need some way to make choices about algorithms.
For example, one might choose the GMRES iterative solver together with an incomplete LU preconditioner to solve linear systems.
The solver classes, as opposed to the model classes, provide the interface for making these choices.
While alternative solvers might offer faster runtime performance than direct factorization, they also requires making additional choices -- how often to restart GMRES?
How much fill-in to allow in the incomplete factorization?
Many glaciologists do not have the background in numerical linear algebra to know that adjusting these parameters could make the difference between solver convergence or breakdown.
As another example, users might want to select between different discretization strategies for the Stokes equations.
The discretization of the Stokes equations has to be chosen carefully in order to satisfy the Ladyzhenskaya-Babu\v{s}ka-Brezzi (LBB) conditions \citep{boffi2013mixed}.
When using Galerkin least-squares stabilization of the weak form, the user has to pick a value of the stabilization parameter.
Determining exactly what value of this parameter is necessary to guarantee stability is a subtle problem, even more so for the kinds of highly anisotropic meshes that are commonly encountered in 3D glacier flow modeling.
If the solver fails to converge, it might not be obvious even to an expert whether the problem lies with the stabilization or the aforementioned parameters of the linear solver.


\section{Discussion}

We have presented a new software package called \emph{icepack} for modeling the flow of glaciers and ice sheets.
This package advances the state of the art in this field by providing a platform for easily experimenting with the model physics.
In this paper, we have presented three demonstrations of this feature:
\begin{enumerate}
    \item coupling a model of ice shelf flow to a phenomenological model of damage,
    \item changing the sliding law in a simulation of a marine-terminating glacier, and
    \item inferring the fluidity of a floating ice shelf in a way that guarantees positivity.
\end{enumerate}
The phyics both of how glaciers flow and of how they interact with their environment are not completely understood.
Consequently, the ability to change components of the model is an essential feature for any tool aimed at researchers in this field.

We have also paid special attention to how we can design this software package to be most usable for its intended audience.
Usability is not often discussed in the literature on computational science.
We believe that this is because of two difficulties: (1) quantifying the degree to which usability is a rate-limiting factor and (2) concretely assessing what features make software tools more or less usable.
By contrast, measuring computational performance is much more feasible although still fraught with difficulties of its own.
(This is not to say that performance optimization is easy by any means.)
In working with several graduate students and postdoctoral researchers in glaciology, we have observed that usability is a substantial bottleneck for researchers at these career stages.
For this reason, we have chosen to focus explicitly on usability by drawing on the research literature in HCI.
We argue that the same design features that enhance usability for relative novices to the subject area will also enhance the productivity of expert users.

This paper has presented several physics models currently implemented in icepack along with demonstrations.
Future developments will include:
\begin{enumerate}
    \item an implementation of full Stokes flow
    \item dynamic glacier termini to enable calving models
    \item adaptivity through moving mesh methods
\end{enumerate}
New features will be guided by feedback from icepack users and from the glaciological community at large.
By providing implementations of several glacier flow models from less to more complex and by enabling users to experiment with the physics, this tool both lowers the barrier to entry for novices to glacier flow modeling and provides a pathway for these users to progress towards ever more sophisticated and advanced simulations.

\bibliographystyle{plainnat}
\bibliography{icepack.bib}

\end{document}
