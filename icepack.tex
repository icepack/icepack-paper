\documentclass{article}

\usepackage{amsmath}
%\usepackage{amsfonts}
\usepackage{amsthm}
%\usepackage{amssymb}
%\usepackage{mathrsfs}
%\usepackage{fullpage}
%\usepackage{mathptmx}
%\usepackage[varg]{txfonts}
\usepackage{natbib}
\usepackage{color}
\usepackage[charter]{mathdesign}
\usepackage[pdftex]{graphicx}
%\usepackage{float}
%\usepackage{hyperref}
%\usepackage[modulo, displaymath, mathlines]{lineno}
%\usepackage{setspace}
%\usepackage[titletoc,toc,title]{appendix}

%\linenumbers
%\doublespacing

\theoremstyle{definition}
\newtheorem*{defn}{Definition}
\newtheorem*{exm}{Example}

\theoremstyle{plain}
\newtheorem*{thm}{Theorem}
\newtheorem*{lem}{Lemma}
\newtheorem*{prop}{Proposition}
\newtheorem*{cor}{Corollary}

\newcommand{\argmin}{\text{argmin}}
\newcommand{\ud}{\hspace{2pt}\mathrm{d}}
\newcommand{\bs}{\boldsymbol}
\newcommand{\PP}{\mathsf{P}}

\title{\emph{icepack}: a novel glacier flow modeling package}
\author{Daniel Shapero}
\date{}

\begin{document}

\tableofcontents
\newpage

\maketitle

\begin{abstract}
In this paper we introduce a new software package called \emph{icepack} for modeling the flow of glaciers and ice sheets.
Icepack is built on the finite element modeling library Firedrake, which uses the domain-specific language UFL for describing weak forms of partial differential equations.
The diagnostic models in icepack are formulated through action principles that are specified in UFL.
The components of each action functional can be substituted for different forms of the user's choosing, which makes it easy to experiment with the model physics.
Many post-processing and analysis tasks on simulation results also amount to the evaluation of some functional.
By using a variational formulation of the model physics, the specification of a problem and the analysis of the solution employ the same conceptual vocabulary.
A third advantage of variational principles is that the action functional itself can be used to define a solver convergence criterion that is independent of the mesh and requires little tuning on the part of the user.
Icepack features a 3D diagnostic model based on terrain-following coordinates and vertical spectral discretization.
This model resolves both plug- and shear-flow components of horizontal ice flow with a minimum of extra computational expense over 2D, depth-averaged models.
Finally, icepack implements a Gauss-Newton solver for inverse problems that runs substantially faster than the standard BFGS method used in the glaciological literature.
The overall design philosophy of icepack is to be as usable as possible for a wide a swathe of the glaciological community, including both experts and novices in computational science.
\end{abstract}

\section{Introduction}

Numerical modeling has become an essential part of the workflow of glaciologists across all disciplines.
We highlight four main uses of glacier models in the literature:
\begin{enumerate}
    \item predicting future glacier extent and estimating the sea-level rise contribution from glacier dynamics,
    \item exploring aspects of glacier physics, such as hydrology and calving, that are not completely understood,
    \item estimating unobservable quantities, such as bed friction or rheology, from observational data, and
    \item reconstructing what glaciers of the near- or distant-past may have looked like.
\end{enumerate}
Nearly all glaciologists, from graduate students to senior researchers, need to use numerical models at some point in their career.
Several glacier flow models already exist and are effective in the hands of experts.
These models are usually written in compiled programming languages such as C, C++, and Fortran for reasons of computational efficiency.
Many researchers in glaciology, however, receive little or no formal programming training, much less in these languages, and are instead self-taught in either Python or MATLAB.
The ubiquity of C, C++, and Fortran in scientific computing can create a barrier to entry for glaciologists who are not experts in high-performance computing.
Our goal is to make a tool that will be both accessible to non-experts and useful for experts.

The glacier flow modeling package closest in spirit to icepack is VarGlaS \citep{brinkerhoff2013data}.
VarGlaS is implemented using the finite element modeling package FEniCS \citep{logg2012automated}.
The Firedrake project began as an outgrowth of FEniCS and both packages implement the same domain-specific language for describing weak forms of PDE.
Icepack improves upon the groundwork laid in VarGlaS in three main respects.
First, icepack includes a simple 3D flow model that uses several features only available in Firedrake: extruded meshes and tensor product finite elements \citep{bercea2016structure, mcrae2016automated}.
This model will be described in section \S\ref{sec:physics-hybrid-model}.
Second, the architecture of icepack is designed to make it easy for users to alter the various physics components, such as the rheology and basal friction, of any of the models included.
The software design that made this possible is discussed in section \S\ref{sec:physics-substitution}.
Finally, the inverse solver in icepack uses the Gauss-Newton method, which converges faster and more reliably than the BFGS method used in VarGlaS; see section \S\ref{sec:numerics-inverse-solvers}.

The two main components of a glacier flow model are a \emph{diagnostic} and a \emph{prognostic} equation.
The diagnostic equation prescribes the ice velocity through a time-independent, nonlinear, elliptic partial differential equation.
The inputs to the diagnostic equation are the ice thickness, surface elevation, velocity at the inflow boundary, rheology, and bed friction coefficient.
The output of the diagnostic equation is the ice velocity throughout the entire domain.
The prognostic equation prescribes how the ice thickness evolves through conservation of mass.
The inputs to the prognostic equation are the current value of the ice thickness, velocity, and the surface and basal mass balance.
The output is the ice thickness at the subsequent timestep.
Mathematically, these two coupled PDEs can be thought of as a differential-algebraic equation.

The rheology and friction coefficient are functions of other fields that have their own evolution equations.
For example, the rheology is a function of temperature, englacial water content, and damage from crevassing.
Likewise, the friction coefficient can be described in terms of the subglacial water pressure and a roughness factor for the underlying bedrock.
The diagnostic and prognostic equations can then be supplemented with evolution equations for these fields, for example the heat equation for temperature, or a hydrology model for subglacial water pressure.


\section{Physics}

\begin{table}[h]
    \begin{tabular}{l|l}
        Symbol & Meaning \\
        \hline
        $h$ & thickness \\
        $b$ & bed elevation  \\
        $s$ & surface elevation  \\
        $d$ & water depth \\
        $u$ & velocity \\
        $\dot a_s$ & surface mass balance \\
        $\dot a_b$ & basal mass balance \\
        $\dot\varepsilon$ & strain rate \\
        $C$ & bed friction coefficient \\
        $A$ & rheology coefficient \\
        $\nu$ & unit outward normal \\
        $J$ & action functional
    \end{tabular}
    \caption{Mathematical symbols}
\end{table}

\begin{table}[h]
    \begin{tabular}{l|l}
        Symbol & Meaning \\
        \hline
        $n$ & Glen's flow law exponent \\
        $m$ & Weertman sliding law exponent \\
        $\rho_I$ & ice density \\
        $\rho_W$ & seawater density \\
        $g$ & gravitational acceleration
    \end{tabular}
    \caption{Physical constants}
\end{table}


\subsection{Mass transport}

The PDE describing how the ice thickness changes in time is a conservative advection equation:
\begin{equation}
    \frac{\partial h}{\partial t} + \nabla\cdot hu = \dot a_s - \dot a_b,
\end{equation}
where $\dot a_s$ and $\dot a_b$ are the surface and basal mass balance.
The thickness is represented using continuous Galerkin basis functions.
The ice thickness and bed elevation are used to update the surface elevation at every timestep, and we need the surface gradient to calculate the driving stress.
The current mass transport implementation in icepack assumes continuous basis functions because this makes for the most straightforward calculation of the ice surface slope, which is part of the driving stress.
Implementing a solver that also works for discontinuous basis functions involves is more challenging but still possible.

The surface elevation is calculated at each timestep of a simulation as
\begin{equation}
    s = \max\{b + h, (1 - \rho_I / \rho_W)h\},
\end{equation}
the first case corresponding to grounded ice and the second case corresponding to floating ice.
In the immediate vicinity of the grounding line, the assumption that the floating ice is in hydrostatic equilibrium with the ocean fails.
Most models assume hydrostasy and icepack does as well.
Elmer/Ice, on the other hand, solves a contact problem for the moving upper and lower ice surfaces and thus can accurately model non-hydrostatic ice shelves \citep{gagliardini2013capabilities}.


\subsection{Momentum transport}

There are three diagnostic models implemented in icepack.
The \emph{shallow ice approximation} (SIA) and \emph{shallow stream approximation} (SSA) are 2D models describing the depth-averaged velocity of ice flow, while the \emph{first-order} or \emph{Blatter-Pattyn} approximation is a 3D model describing the horizontal velocity (termed the \emph{hybrid model} in icepack) \citep{blatter1995velocity, pattyn2003new}.
The SIA model \citep{hutter1981effect} describes the interior of ice sheets well, where flow can be simply described as bed-parallel shear and surface and basal slopes are small.
This approximation breaks down near ice divides, where vertical velocities dominate, and near ice margins, where basal sliding can be a large fraction of the surface speed.
The SSA model describes the fast-flowing margins of the ice sheet best, encompassing grounded ice streams or floating ice shelves \citep{macayeal1989large}.
This model is appropriate where the sliding velocity is close to the surface velocity, or in other words where the ice is nearly in plug flow.
Plug flow is a good approximation in fast-flowing ice streams and outlet glaciers near the margins of an ice sheet, but deep in the interior the flow is mostly by vertical shear.
The only approximation in the hybrid model is that the flow has a low aspect ratio -- the thickness of the glacier is much less than its horizontal extent.
This approximation may be questionable around, say, the main trunk of Jakobshavn Isbrae in Greenland, which flows through a very deep and narrow trough.
Even Jakobshavn has an aspect ratio on the order of 1/5 and almost all glacier flows have an aspect ratio less than 1/10 or even 1/20.

\textcolor{red}{Should Glen's flow law be mentioned or written somewhere?}

\subsubsection{Variational principles}

All of the diagnostic models in icepack are described through \emph{variational} or \emph{action} principles \citep{dukowicz2010consistent}.
Rather than describe the velocity as the weak solution of a nonlinear PDE, an action principle instead states that the velocity minimizes a functional called the action.
The action consists of four terms:
\begin{align}
    & \text{action} = \iint\text{stress} \times \text{strain rate}\ud z\ud x - \int\text{basal friction} \times \text{sliding velocity}\ud x \nonumber \\
    & \quad - \iint\text{surface slope}\times\text{velocity}\ud z\ud x - \iint\text{ocean pressure}\times\text{velocity}\ud z\ud \gamma
    \label{action-functional}
\end{align}
where $\ud z\ud x$ denotes integration over the entire glacier, $\ud x$ denotes integration over the glacier footprint, and $\ud z\ud\gamma$ over the side wall boundary.
The action has units of power (energy/time) and can be related to the rate of decrease of the thermodynamic free energy.
Moreover, the energy lost to viscous and frictional heating can be calculated from the action and its Legendre transform.
The action principle can be viewed as a consequence of the Onsager reciprocity relations for systems near to equilibrium \citep{de2013non}.

The action principle is especially useful for designing a robust numerical solver.
For viscous flow problems near to steady-state, the action is \emph{convex} as a function of the ice velocity, i.e. its second derivative is positive-definite.
Convexity implies that the action functional has a unique minimizer and that, with an appropriate line search strategy, Newton's method will converge from any initial guess.
Minimizing a convex action functional is vastly more convenient numerically than solving a general nonlinear equation, although the two formulations are equivalent.

\subsubsection{Shallow ice approximation}

The shallow ice model can be derived from the Blatter-Pattyn approximation by assuming the ice flow is dominated by bed-parallel shear and that surface and basal slopes are small, i.e. $\partial u/\partial x \ll \partial u/\partial z$.
The result is a 2D system of equations for depth-averaged horizontal velocity.
The terms in the action functional are:
\begin{align}
    \text{mass} & =\frac{1}{2}\int_\Omega u\cdot u\ud x\\\
    \text{gravity} & = \int_\Omega\frac{2A(\rho_I g)^n}{n+2} h^{n + 1}|\nabla s|^{n - 1}\nabla s\cdot u\ud x\\
    \text{penalty} & = \frac{1}{2}\int_\Omega \ell^2\nabla u\cdot \nabla u\ud x
\end{align}
and the action fuctional is
\begin{equation}
    J = \text{mass} + \text{gravity} + \text{penalty}.
\end{equation}
The default value of the length scale $\ell$ in the penalty term is defined as:
\begin{equation}
    \ell = 2\max\{\text{cell diameter}, 5h\}
\end{equation}
but users can adjust this to the value of their choice.
This penalty term smooths over numerical artifacts, especially near the ice margins and termini.
In these regions the shallow ice approximation is less applicable, so the error in solving a different set of equations is small compared to the inherent modeling error in using these equations in the first place.

The shallow ice approximation applies well in ice-sheet interiors.
For this reason, and because the equations are particularly simple to solve, this approximation has been a common choice for ice-sheet modeling \textcolor{red}{cite}.
Caution must be taken, however, because areas of the ice sheet that experience high vertical velocities (e.g., ice divides) or plug flow (e.g., ice streams) are not well represented by this approximation.

\subsubsection{Shallow stream approximation}

The shallow stream model can be derived from the Blatter-Pattyn approximation by assuming nearly plug flow, i.e. $\partial u/\partial z \ll \partial u/\partial x$.
In this case, the momentum equation can be vertically integrated to obtain a 2D system of equations.
The terms in the action functional are:
\begin{align}
    \text{viscosity} & = \frac{n}{n + 1}\int_\Omega hA^{-\frac{1}{n}}|\dot\varepsilon(u)|^{\frac{1}{n} + 1}\ud x \\
    \text{friction} & = \frac{m}{m + 1}\int_\Omega C|u|^{\frac{1}{m} + 1}\ud x \\
    \text{gravity} & = -\int_\Omega\rho_I gh\nabla s\cdot u\ud x \\
    \text{terminus} & = \frac{1}{2}\int_\Gamma(\rho_I gh^2 - \rho_Wgd^2)u\cdot \nu\ud\gamma
\end{align}
and the action functional is
\begin{equation}
    J = \text{viscosity} + \text{friction} - \text{gravity} - \text{terminus}.
\end{equation}
When the ice is floating, there are two simplifications: the friction coefficient $C$ is 0, and the surface elevation $s$ can be written in terms of the thickness $h$ as
\begin{equation}
    s = (1 - \rho_I / \rho_W)h.
\end{equation}
Using integration by parts, the terminus component can be eliminated completely.

Several studies have compared the shallow stream approximation to higher-order models, such as Blatter-Pattyn or full Stokes \textcolor{red}{cite the MIPs}.
The most appreciable difference between lower- and higher-order models occurs near the glacier grounding line, where the full Stokes equations can represent bridging stresses \textcolor{red}{cite van der Veen}.
The shallow stream approximation is warranted for studying individual fast-flowing glaciers where the concern is more with studying processes and responses than with complete accuracy.


\subsection{Hybrid model} \label{sec:physics-hybrid-model}

The shallow ice and shallow stream models in icepack follow directly from the variational principles described above.
The hybrid flow model, while also based on a variational principle, uses two more tricks: terrain-following coordinates and vertical spectral methods.
Each of these methods has appeared in the literature on glacier modeling before but never all in the same place for a 3D model.
\citet{langdon1978numerical} and \cite{bassis2010hamilton} used variational principles and vertical spectral methods, but these works considered only flowband and not 3D models.
\citet{kleiner2014numerical} used terrain-following coordinates for 3D glacier flow modeling, but they discretized the problem with finite difference methods in every direction and did not take into account the variational formulation of the diagnostic model.
\citet{jouvet2015multilayer} used vertical semi-discretization of the variational problem, but this model used a finite difference discretization in the vertical direction.

\subsubsection{Terrain-following coordinates}

Rather than use the usual Cartesian coordinate system, the hybrid flow model uses terrain-following coordinates.
The terrain-following vertical coordinate $\zeta$ is
\begin{equation}
    \zeta = \frac{z - b}{h}
\end{equation}
where $b$ is the ice base.
We can then think of the computational domain as the Cartesian product of a 2D footprint domain $\Omega$ and the unit interval $[0, 1]$.

Both the bed elevation and thickness depend on $x$ and $y$.
As a result, the formula for the horizontal gradient of a field in terrain-following coordinates includes an additional geometric correction factor.
Letting $\nabla_z$ and $\nabla_\zeta$ denote the horizontal gradient with respectively $z$ and $\zeta$ held constant, the chain rule gives us that
\begin{equation}
    \nabla_zq = \nabla_\zeta q + \frac{\partial q}{\partial\zeta}\nabla\zeta,
\end{equation}
where we can calculate the spatial gradient of $\zeta$ as
\begin{equation}
    \nabla\zeta = -h^{-1}\left\{(1 - \zeta)\nabla b + \zeta\nabla s\right\}.
\end{equation}
Likewise, the strain rate of a vector field can be expressed as
\begin{equation}
    \dot\varepsilon_z(u) = \dot\varepsilon_\zeta(u) + \frac{1}{2}\left(u \otimes\nabla\zeta + \nabla\zeta\otimes u\right)
    \label{eq:geometric-correction}
\end{equation}
where $\otimes$ is the tensor product of two vectors.

For the Stokes equations, this alternative coordinate system also helps avoid the problem of how to enforce the condition $u\cdot \nu = -\dot a_b$ at the ice base, where $\nu$ is the unit outward normal vector and $\dot a_b$ is the basal mass balance.
This boundary condition is difficult to impose exactly because the unit outward normal vector $\nu$ is defined on mesh faces while the velocity is defined at mesh vertices.
Elmer/Ice uses an ad-hoc procedure to define the unit normal vectors at mesh nodes \citep{gagliardini2013capabilities}.
This procedure is nearly always effective in practice.
But with a transformation to terrain-following coordinates, we can set the terrain-following vertical velocity $\omega$ to be $-\dot a_b/h$ at the ice base to impose this boundary condition with no additional intervention.

We also argue that answers expressed in terrain-following coordinates are more intuitive in some respects than in Cartesian coordinates.
At the bed of a grounded glacier, the vertical velocity in Cartesian coordinates is
\begin{equation}
    w = -\dot a_b + u\cdot\nabla b.
\end{equation}
Knowing that a model gives a vertical velocity at the base of a glacier of, say, 10 cm/year, the modeler needs to also know the bed slope and sliding velocity.
In other words, it is not immediately clear whether the vertical velocity is a result of basal mass balance or of geometry without additional information.
By contrast, the vertical velocity $\omega$ in terrain-following coordinates evaluated at $\zeta = 0$ is completely determined by basal mass balance and ice thickness.


\subsubsection{Spectral discretization}

Terrain-following coordinates open up several choices for how to describe the vertical variation of the velocity field.
In Elmer/Ice, for example, the user can extend the finite element discretization into a number of vertical layers.
The number of vertical layers is a user-tuneable parameter, depending on the desired resolution along this axis \citep{gagliardini2013capabilities}.

The horizontal velocity for many realistic flows is very smooth as a function of depth and this suggests a different approach.
For example, under the plug flow approximation, the horizontal velocity is constant with depth.
Under the shallow ice approximation, the horizontal velocity varies with depth as $1 - (1 - \zeta)^{n + 1}$ where $n = 3$ is the Glen flow law exponent.
This extra information about our solution suggests a modal rather than a nodal discretization strategy.

Rather than divide the spatial domain into many vertical layers, we can instead use only one vertical layer and increase the polynomial degree in the vertical direction to obtain higher resolution.
This type of basis, in which different shape functions are used in different dimensions, is called a \emph{tensor product} element.
Given a set of finite element basis functions $\{\phi_k(x, y)\}$ defined on the 2D domain $\Omega$ and a set of basis functions $\{\psi_l(\zeta)\}$ defined on the unit interval $[0, 1]$, the tensor product finite element basis $\{\Phi_{kl}\}$ on the extruded domain is defined as
\begin{equation}
    \Phi_{kl}(x, y, \zeta) = \phi_k(x, y)\psi_l(\zeta).
\end{equation}
For example, we can use piecewise linear or quadratic elements on triangles and use quintic or higher degree polynomials in the vertical.
Rather than use the usual Lagrange interpolating polynomial basis in the vertical dimension, we can instead use the Legendre polynomial basis.
The Legendre polynomials are mutually orthogonal and this choice makes the mass matrix block-diagonal.

The combination of using extruded meshes and tensor product elements in the vertical direction is referred to as \emph{semi-discretization}.
This approach can be thought of merely as a way to discretize a PDE that has special structure.
Alternatively, we can view vertical semi-discretization as defining a family of models indexed by the number of vertical basis functions.
The order-$d$ model defines a coupled system of PDEs for $d$ vector fields.
Each vector field represents one mode of vertical variability, similar to the distinction between barotropic and baroclinic modes in atmospheric physics and oceanography.
The system is then discretized in the horizontal and solved numerically.
In any case, the code is the same regardless of how one views the underlying mathematics.

The user then has to decide how many vertical modes are enough.
Using only degree 0 is exactly equivalent to the shallow stream approximation and we use this fact as a ``smoke test'' for the hybrid model.
The degree 2 model is the most minimalistic model that still exhibits vertical shear and can satisfy the zero-stress boundary condition at the ice surface.
Going to higher degree gives a more accurate approximation at the expense of greater computational effort.

\subsection{Substituting model components} \label{sec:physics-substitution}

Many aspects of glacier physics are not completely understood.
For example, the most common description of basal friction assumes that glacier sliding occurs through regelation, in which case the basal shear stress can be written
\begin{equation}
    \tau_b = -C|u|^{\frac{1}{m} - 1}u
    \label{eq:weertman-sliding}
\end{equation}
with $m = 3$ \citep{weertman1957sliding}.
Many authors have argued that, in fast-flowing regions of the ice sheet, glacier sliding occurs instead by plastic deformation within the subglacial sediments \citep{tulaczyk2000basal}.
For plastic sliding, the shear stress is dependent on the yield strength of the subglacial sediments and not on the sliding speed, in which case $m = \infty$ would be most appropriate.
Finally, the Schoof sliding law aims to reconcile the two modes of sliding \citep{schoof2005effect}.
Below a critical sliding speed, the shear stress is aymptotic to $|u|^{1/m}$ as in the Weertman sliding law, but above the critical speed the shear stress is independent of the sliding speed.

The Weertman and plastic sliding laws possess the same functional form but differ only in the value of a single scalar parameter $m$.
The Schoof sliding law, on the other hand, has a totally different functional dependence on the velocity.
Several authors, including Schoof, have proposed that the basal shear stress is also a function of the effective pressure $N = \rho gh - p_w$ within the subglacial hydrological system \citep{budd1979empirical, schoof2005effect}.
Implementing these more sophisticated mathematical models would require adding an extra argument to the procedure for solving the diagnostic equation.

One of our goals with icepack is to facilitate experimentation with the model physics.
To support use cases like implementing the Schoof sliding law, it must be possible to completely alter the functional form of a given model physics component.
For uses cases like explicitly adding the dependence of basal shear stress on hydrology, it must also be possible to add entirely new fields to a given model physics component.
In programming terms, this amounts to changing the number of arguments to the function that calculates basal shear stress.
For a library developed in C or Fortran, the user would then also have to change the signature of the diagnostic solve function.
In C++ one could avoid changing the signature of the diagnostic solve routine in several ways.
First, the function signature could be expressed using variadic templates.
This is an advanced language feature and relying on it would present a steep learning curve for novices.
Second, the inputs could be wrapped up in a class.
Users can then define a subclass if they need to change the input fields.
This would be a fairly idiomatic approach for the language but requires users to know more about object-oriented programming than the approach we'll describe below.
Finally, the inputs could be wrapped in a dictionary (a \texttt{std::map} from the C++ standard library).
This approach sacrifices the static type checking guarantees of C++, one of the main advantages of the language.
At this rate there is little marginal gain over using a dynamically-typed language such as Python.

Any model physics component in icepack can be substituted for a parameterization of the user's choosing.
Each flow model object is initialized with a set of functions to calculate the various terms of the action functional.
For example, the ice stream model is initialized with functions to calculate the contributions due to viscosity, basal friction, side wall drag, and gravity.
The default parameterizations are set to the most common choices in the literature, but if the user does wish to change a given component, they can pass a function that they write to the initializer for the model object.
When the diagnostic solve procedure is invoked, all of its arguments are then passed on by keyword to the method that calculates the action functional.
Any fields that are unnecessary for calculating a given component are ignored.
For example, the rheology and friction coefficient are passed to the function that calculates the gravitational driving power, and this function makes no use of these arguments.
The user can completely change the functional form and add new arguments, with the restriction that arguments are passed by keyword and not positionally.

In adopting this approach, we are restricted to using keyword arguments instead of positional arguments.
We argue that employing only keyword arguments enhances readability and comprehensibility for the particular user case of calling a physics solver.
The user only needs to know the argument names, which are chosen to agree with the English name most commonly used in the literature -- ``friction'', ``rheology'', ``velocity'', etc.
The order of the arguments is arbitrary and immaterial.
The preference for argument passing by name is specific to this use case and not universal.
For example, in defining a bilinear form that represents a non-symmetric PDE, the order of the arguments has intrinsic mathematical significance.
Positional arguments correspond better with the semantics of the problem in this case than keyword arguments.

One of our main design goals for icepack is to enable users to ``plug and play'' their own physics.
Since many aspects of glacier flow are not understood completely, we view extensibility as an essential requirement for any software package in this domain.
Writing the entire package in Python was necessary to meet this goal.
Many scientific software packages consist of a highly-optimized core library in C, C++, or Fortran, together with a wrapper that exposes this library to an interpreted language like Python.
This approach in principle offers the best of both worlds -- the runtime efficiency of a compiled language with the convenience and interactivity of an interpreted one.
Many practitioners, however, will use such a library entirely through the interpreted surface layer and have no familiarity with the language in which the fast core was written.
These users then have a steep learning curve to overcome when they need to modify functionality that lives in the core library, as they now need to learn an entirely new programming language.
Some low-level kernel code is always necessary for runtime efficiency but with Firedrake this responsibility is deferred to a code generator.
The average user can remain largely unaware of how the code generator works even when solving very advanced problems.


\subsection{Data assimilation}

Icepack includes a set of routines for estimating the basal friction or rheology coefficients from observational data.
The class \texttt{InverseProblem} represents the specification of the inverse problem.
To specify an inverse problem, the user must provide:
\begin{itemize}
    \item the model object and the method that solves the diagnostic equation,
    \item the objective and regularization functionals,
    \item the observed field and the name of the argument to the diagnostic solver,
    \item an initial guess for the field to be estimated and the name of the argument to the diagnostic solver,
    \item extra data passed to the diagnostic solver such as boundary conditions.
\end{itemize}
At present, this class assumes that the observed state is always the ice velocity, but in principle the same design would suffice for more complicated inverse problems.
More importantly, the inverse problem is flexible enough to account for the fact that we might have substituted in our own parameterization for the rheology or friction coefficient.
For example, nearly all studies in the literature use an alternate parameterization of the friction coefficient in terms of some auxiliary field in order to guarantee positivity \citep{macayeal1992basal, joughin2009basal}.
This information is passed to the inverse problem by specifying the names of the keyword arguments for the observed state and the field we wish to observe.

The \texttt{InverseSolver} class is responsible for actually solving the inverse problem.
This class will be described further in section \S\ref{sec:numerics-inverse-solvers}.
The inverse solver is completely agnostic to the particular parameterization of the physics in terms of the inferred field as long as it guarantees positivity.
This feature interacts seamlessly with the ability to modify individual model physics components as described in \S\ref{sec:physics-substitution}.


\subsection{Damage transport}

\subsection{Heat transport}


\section{Numerics}

In this section we describe how various parts of the model physics were implemented in icepack, including both software design and the numerical solution procedures.
The key classes that users interact with are flow models and solvers.
The role of the model classes is to describe what problem is being solved.
These classes describe the diagnostic model by taking in the input fields -- ice velocity, thickness, surface elevation, etc. -- and returning a symbolic representation of the action functional.
There are several model classes, one for each set of physics equations: \texttt{ShallowIce}, \texttt{IceShelf}, \texttt{IceStream}, \texttt{HybridModel}.
The model classes do not dictate how that problem should be solved numerically; this is the realm of a separate class called \texttt{FlowSolver}.
This flow solver class has methods for computing the solutions of the diagnostic and prognostic equations and works the same regardless of which model is being solved.
The diagnostic solve method amounts to invoking an external Newton solve procedure on the symbolic action functional that the model object creates.
The Newton solver itself is completely standard but the convergence criterion is not and will be discussed in section \S\ref{sec:convergence-criteria}.
Finally the flow solver has a method to update the ice thickness from the current value, the ice velocity, and the mass balance rates.
The prognostic solver will be discussed in section \S\ref{sec:prognostic-model}.

The Unified Form Language for specifying weak forms of PDEs contains all of the primitives necessary to express individual terms of the action functional.
These primitives consist of the basic vector calculus operators like the gradient of a field, tensor calculus operations like taking the dot product of two vectors or tensors, scalar functions like the square root or exponential, and symbolic integration over the mesh or its boundary.
For example, the strain rate for a given velocity field $u$ can be written as \texttt{sym(grad(u))}, where the function \texttt{grad} represents the symbolic gradient of a field and \texttt{sym} represents the symmetrization of a rank-2 tensor.


\subsection{Advective transport} \label{sec:prognostic-model}

The simplest explicit timestepping schemes are unstable with continuous Galerkin finite elements.
To solve the mass transport equation, other packages use the streamlined upwind Petrov-Galerkin (SUPG) method for the timestepping scheme \citep{brinkerhoff2013data, larour2012continental}.
The SUPG method with an explicit time discretization is conditionally stable \citep{donea2003finite}.
This scheme introduces a tuneable stabilization parameter, so in the interest of simplicity we instead default to the implicit Euler scheme.
The implicit Euler scheme requires solving a non-symmetric linear system, but the computational cost comes with the advantage of unconditional stability.

Practicing glaciologists who have not studied numerical PDE may be unfamiliar with the Courant-Friedrichs-Lewy condition.
The use of an unconditionally stable scheme guarantees that they will get an answer should they try to use a large timestep rather than a runtime error.
The extra cost of using an implicit time discretization for the mass transport equation is dwarfed by the cost of the diagnostic solve in any case.
Advanced users who are interested in maximizing performance can subclass the mass transport solver to implement a faster explicit scheme.

The implicit Euler scheme tends to diffuse out sharp discontinuities that may be present in the true solution \citep{donea2003finite}.
Since the ice thickness does not possess shockwaves or propagating discontinuities this error mode is tolerable.
The coupling of ice thickness to velocity makes the whole system more resemble a parabolic problem than a hyperbolic one, and under the shallow ice approximation the system is truly parabolic.
Other problems within glaciology have more of a hyperbolic character and there the argument for using shock-capturing methods is much stronger.
For example, in continuum damage mechanics, the thresholding behavior of the source terms can induce sharp discontinuities in the damage field \citep{albrecht2014fracture}.
The implicit Euler scheme would obscure this feature and an alternative method such as the strong stability-preserving Runge-Kutta method would be more appropriate.


\subsection{Convex optimization}

The action functional for each diagnostic model is convex, i.e. the second derivative is strictly positive-definite.
From a theoretical persepctive, convexity guarantees that the problem has a unique solution.
This property is also especially advantageous for implementing numerical solvers.
We use a damped Newton method to solve the diagnostic equations.
Starting from a guess $u_k$ for the velocity, the \emph{search direction} $v_k$ is the unique solution of the linear system
\begin{equation}
    \ud^2J(u_k)\cdot v_k = -\ud J(u_k).
    \label{eq:newton-search-direction}
\end{equation}
The next approximation for the velocity minimizes $J$ along the search direction $v_k$ starting from $u_k$, i.e.
\begin{align}
    u_{k + 1} & = u_k + \alpha_k\cdot v_k, \nonumber\\
    \alpha_k & = \text{argmin}_\alpha \hspace{2pt}J(u_k + \alpha v_k).
\end{align}
For an initial guess sufficiently close to the exact solution, the undamped Newton method ($\alpha_k = 1$ at every step) converges quadratically.
The line search step ensures that the method can converge even from a poor initial guess, provided that the line search method satisfies the Armijo-Wolfe criteria \citep{nocedal2006numerical}.

For a convex problem, $\ud^2J$ is a symmetric and positive-definite matrix.
This has two advantages.
First, the search direction is always a descent direction for $J$.
For non-convex problems this is not always the case and some adaptation strategy must be employed in the vicinity of saddle points.
Second, symmetry and positivity enable the use of specialized linear solvers, such as the Cholesky decomposition or the conjugate gradient algorithm, that are superior to their more general counterparts in many respects.

Other software packages that treat diagnostic models as nonlinear systems of equations tend to rely on ad-hoc procedures for initializing the numerical solution process.
For example, without a damping procedure in Newton's method, the iteration can prove unstable if initialized far away from the true solution.
Some packages combat this problem by using a few iterations of the more robust but slower Picard method first \citep{gagliardini2013capabilities}.
While this approach can be effective it requires tuning the number of Picard iterations and there is no guarantee that an adequate amount for one problem will work well on another problem.
This issue rarely appears on realistic input data.
When solving inverse problems, however, the intermediate guesses for the inferred field can be wildly unrealistic before converging.
A forward model solver that is not sufficiently robust can crash in these extreme scenarios.
By contrast, a damped Newton procedure using a line search that satisfies the Armijo-Wolfe criteria is guaranteed to converge on non-degenerate, if unrealistic, input data.


\subsection{Convergence metrics} \label{sec:convergence-criteria}

Several works in the literature have weighed the relative merits of different iterative methods for solving the nonlinear diagnostic equation \textcolor{red}{cite -- I think Mathieu and Dan did this}, but few if any have considered the problem of when to stop iterating.
The most common stopping criteria are when (1) the 2-norm of the residual is sufficiently small or (2) the relative change in the iterates is sufficiently small.
Each of these approaches has problems.
The residual norm depends on the discretization and does not weight all degrees of freedom proportionally, e.g. vertex and edge degrees of freedom in higher-order finite element methods.
The relative change criterion, on the other hand, can suggest convergence when in fact the method has stagnated.

A convergence criterion that works equally well independent of the mesh, finite element discretization, and the quality of the initial guess can be defined based on the idea of the \emph{Newton decrement} \citep{nocedal2006numerical}.
Since the second derivative operator $\ud^2J(u_k)$ is positive-definite, the Newton search direction $v_k$ computed from equation \eqref{eq:newton-search-direction} is a descent direction for $J$:
\begin{equation}
    \ud J(u_k)\cdot v_k < 0.
\end{equation}
The absolute value of the quantity in the last equation is defined as the Newton decrement.
For $u_k$ sufficiently close to the true solution $u$, the Newton decrement roughly tells us how much we can expect the action to decrease:
\begin{equation}
    J(u_k) - J(u) \approx \frac{1}{2}|\ud J(u_k)\cdot v_k|.
\end{equation}
We can then use the Newton decrement to decide when to stop the iteration.

As shown in equation \eqref{action-functional}, the action has units of power and is the sum of the dissipation due to viscosity, friction, gravitational driving, and ocean back-pressure at the terminus.
The viscous and frictional terms are convex, positive functions of the velocity.
The gravitational and terminus stress terms are linear in the velocity and can be of either sign.
If we define the \emph{scale functional}
\begin{equation}
    K(u) = \text{viscous dissipation} + \text{frictional dissipation}
\end{equation}
as only the positive parts of the action, then the convergence criterion
\begin{equation}
    |\ud J(u_k)\cdot v_k| < \epsilon K(u_k)
\end{equation}
is independent of the discretization.
The intuition behind this criterion is that the iteration is halted when the expected decrease in the action functional is much smaller than the positive part of the action itself.

We have found empirically that, with this criterion and the Newton solver implementation in icepack, the iteration usually converges to machine precision in around 8 steps.
The iteration count can reach as high as 20 for exceptionally bad initial guesses for the velocity or with unphysical fluidity or friction values.
We also observe the expected doubling of the number of accurate digits in the value of the action once the velocity guesses are within the convergence basin of the true solution.
Other convergence criteria, such as using relative change in the velocity guesses, can terminate prematurely when the initial guess is very far outside the quadratic convergence basin.

The numerical solvers in icepack have been designed so that users who are not familiar with numerical optimization need not be confronted with a possibly bewildering array of algorithmic parameters.
Consequently, sensible defaults have been chosen for the Armijo and Wolfe criteria \citep{nocedal2006numerical}, and the tolerance for the line search is chosen based on that of the outer-level Newton iteration.
The Newton search direction is calculated using a direct factorization solver rather than, say, the conjugate gradient algorithm, as the use of another iterative method would introduce yet another algorithmic parameter.
Advanced users who are interested in performance optimization can change these algorithmic parameters by passing extra arguments to the solve procedure.


\subsection{Inverse solvers} \label{sec:numerics-inverse-solvers}

The \texttt{InverseProblem} class describes what problem is being solved, while the \texttt{InverseSolver} class is responsible for carrying out the numerical optimization.
There are three inverse solvers in icepack: a simple gradient descent solver, a quasi-Newton solver based on the BFGS approximation to the Hessian, and a Gauss-Newton solver.
All of these classes are based around the general idea of first computing a search direction and then performing a line search.
They differ in how the search direction is computed.

The gradient descent solver uses the search direction
\begin{equation}
    \phi_k = -M^{-1}\ud J(\theta_k)
\end{equation}
where $M$ is the finite element mass matrix.
Gradient descent is a popular choice because the objective functional is always decreasing along this search direction.
However, the search direction can be poorly scaled to the physical dimensions of the problem at hand.
This method can be very expensive and brittle in the initial iterations and often takes many steps to converge.

The BFGS method uses the past $m$ iterations of the algorithm to compute a low-rank approximation to the inverse of the objective functional's Hessian matrix; see \citet{nocedal2006numerical} for a more in-depth discussion.
The BFGS method converges faster than gradient descent.
However, it suffers from many of the same brittleness issues in the initial iterations before it has built up enough history to approximate the Hessian inverse.

Finally, the Gauss-Newton solver defines an approximation to the ``first-order'' part of the objective functional Hessian.
Each iteration of Gauss-Newton is more expensive than that of BFGS or gradient descent because it requires the solution of a more complex linear system than just the mass matrix.
The Gauss-Newton method converges fastest by far in virtually every test case we have found, in some instances by up to factor of 50.

The derivative of the objective functional with respect to the unknown parameter is calculated using the symbolic differentiation features of Firedrake.
The user does not need to provide any routines for the derivatives, only the symbolic form of the error metric and the regularization functional.
The model object is responsible for providing the symbolic form of the action functional.


\subsection{Hybrid model}

The hybrid flow uses several features that are only available in Firedrake to better exploit the special structure of the problem.
Implementing this model also required some mathematical sleight-of-hand related to the terminus boundary condition that has not appeared in the literature before.
Additionally, the hierarchical structure of spectral basis functions presents an opportunity for developing fast algorithms.
In all other respects the implementation of the hybrid flow model using convex optimization follows the techniques described above.

\subsubsection{Discretization}

In order to use terrain-following coordinates, the hybrid model assumes that the geometry of the domain is an extruded mesh, where a 2D footprint mesh is lifted into 3D.
Firedrake includes support for creating extruded meshes by calling the function \texttt{ExtrudedMesh} on the 2D footprint \citep{bercea2016structure}.
The cells of an extruded mesh are triangular prisms instead of the more common tetrahedra used for general 3D meshes.
Not every 3D domain can be described by extruding a 2D domain, but the geometry of most glacier flow problems can.

The geometric correction factor in equation \eqref{eq:geometric-correction} for gradients in terrain-following coordinates can easily be represented in UFL.
By defining a wrapper around the UFL \texttt{grad} function, the code to define the action functional in terrain-following coordinates is only slightly more complex than in Cartesian coordinates.

For problems defined on extruded geometries, Firedrake includes support for tensor product elements, which includes using different bases in the horizontal and vertical directions \citep{mcrae2016automated}.
Tensor product elements are defined in Firedrake by passing the extra keyword arguments \texttt{vfamily}, \texttt{vdegree} to the constructor for a function space.
In our case, we used the usual continuous Galerkin basis in the horizontal and Gauss-Legendre elements in the vertical.
To select the Legendre polynomial basis, the user passes the keyword argument \texttt{vfamily=`Gauss-Legendre'} or \texttt{`GL'} for short to the constructor for the function space.

Extruded meshes and tensor product elements are available in Firedrake but not in FEniCS.
Other general-purpose finite element modeling packages that support tensor product elements include deal.II and nektar++ \citep{bangerth2007deal, cantwell2015nektar++}.
Like most other packages in this domain, deal.II and nektar++ are written in C++, whereas our goal for icepack was to have both the core and the user interface in Python.

\subsubsection{Ocean boundary condition}

Our approach for implementing a hybrid flow model works completely seamlessly but for one important detail.
The backpressure from ocean water at the calving front of a marine-terminating glacier is not a smooth function of depth.
The pressure is 0 above the water line and linearly increasing below it:
\begin{equation}
    \text{backpressure power} = \int_\Gamma\int_0^1 \rho_Wgh(\zeta_{\text{sl}} - \zeta)_+\ud\zeta\ud\gamma,
    \label{backpressure}
\end{equation}
where $\zeta_{\text{sl}}$ denotes the relative depth to the water line and the subscript $+$ denotes the positive part of a real number.
Were we to use the standard asssembly procedure in Firedrake to evaluate this integral, we would get an inaccurate result due to an insufficient number of integration points.
The resulting velocity solutions are then wildly inaccurate due to the mis-specification of the Neumann boundary condition.
A blunt solution to this problem would be to pass an extra argument to the Firedrake form compiler that specifies a much greater integration accuracy in the vertical for this term.
This fix reduces the errors in the velocities, but it does not eliminate them completely and it incurs a large computational cost.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/legendre/pressure.png}
    \caption{The normalized ocean pressure ($p_w / \rho_Wg$) and Legendre polynomial approximations of several degrees (left), and the residuals of the approximation (right).
    For this particular example, the waterline is at $\zeta = 1/3$.
    The moments of each of the residuals up to the approximation degree are all zero.}
    \label{fig:legendre}
\end{figure}

We instead implemented a routine that symbolically calculates the Legendre polynomial expansion of the function $(\zeta_{\text{sl}} - \zeta)_+$ with respect to the parameter $\zeta_{\text{sl}}$ using the package SymPy \citep{sympy}.
The symbolic variables for $\zeta$ and $\zeta_{\text{sl}}$ used in the SymPy representation of the polynomial expansion are then substituted for equivalent symbolic variables in Firedrake/UFL using the SymPy object's \texttt{subs} method.
The Legendre polynomial approximation to this function only converges linearly as the number of coefficients is increased, since the the function is continuous but not smooth, and the approximation exhibits noticeable ringing artifacts at high degree.
While the approximation itself is not very accurate, the calculated value of the integral in equation \eqref{backpressure} is exact because of the orthogonality property of Legendre polynomials.
Stated another way, the residuals in the approximation are large, but they integrate to 0 when multiplied by any Legendre polynomial up to the number of vertical modes.
An example of the pressure approximations using linear, quadratic, and cubic Legendre polynomials are shown in figure \ref{fig:legendre}.

The exact symbolic integration approach is both faster and more accurate than using a large number of quadrature points.
The same technique could be used to exactly calculate the ocean backpressure for any model, say the full Stokes equations, using terrain-following coordinates together with a Legendre polynomial expansion in the vertical.


\subsubsection{Multigrid-type algorithm}

One of the main advantages of this hybrid model is the ease with which a more accurate solution can be bootstrapped from a less accurate solution, since the two fields are defined on exactly the same geometry.
For example, if we only have a very crude initial guess for the solution, we can obtain a degree-1 solution relatively cheaply.
The resulting velocity field is then used as a much more informed initial guess for a degree-5 solution.
\textcolor{red}{Benchmark.}
Since the vertical basis functions are orthogonal, the projection of the degree-1 solution into the degree-5 function space can be calculated by simply copying array elements.
By contrast, if we tried to use the same strategy to bootstrap a solution with a small number of vertical layers to a solution with a larger number of vertical layers, we would also have to interpolate values to the fine layers.

Other hybrid models in the literature use only a fixed number of vertical basis functions.
For example, \citet{bassis2010hamilton} use only the two vertical basis functions $\psi_1(\zeta) = 1$, $\psi_2(\zeta) = 1 - (1 - \zeta)^{n + 1}$, the idea being that the vertical profile can be written as a direct superposition of the plug flow and shallow ice approximation modes.
By contrast, we leave the number of vertical basis functions up to the user.
This flexibility enables the multigrid-type approach described above.

The bootstrapping approach described here can be used both for the forward model and for inverse problems.
First, we estimate the unknown parameter using only degree-1 vertical basis functions for the velocity field, which captures most of the spatial variability of the unknown parameter.
The resulting coefficient is then used as the initial guess with higher degree vertical basis functions for the velocity \textcolor{red}{benchmark}.



\section{Demonstrations}

\subsection{MISMIP+}

As a first test case for icepack, we ran the first experiment from the Marine Ice Sheet Model Intercomparison Project version 3 (MISMIP+).
The parameters and geometry for this experiment can be found in \citet{asay2016experimental}.
The MISMIP+ experiment has three phases.
First, the model must find a steady state marine ice sheet with a fixed accumulation rate and no submarine melting.
Next, submarine melting with a given depth-dependent parameterization is applied for 100 years.
The increased melt thins the ice ice shelf and initiates a retreat of the glacier grounding line.
Finally, submarine melting is turned off for at least 100 years, optionally longer.
The grounding line then readvances, but not as far as its original position.

The original intercomparison project specified that participants could use the Weertman sliding law (equation \eqref{eq:weertman-sliding}) as well as two other sliding laws that transition to a more plastic rheology at high sliding speeds.
The first alternative sliding law consists of Weertman sliding until the stress reaches a critical value, at which point the constitutive relation transitions to perfect plasticity.
The second alternative is the Schoof sliding law \citep{schoof2005effect}:
\begin{equation}
    \tau_b = -\frac{C|u|^{1/m}\cdot \tau_c}{(C^m|u| + \tau_c^m)^{1/m}}\frac{u}{|u|},
    \label{eq:schoof-sliding}
\end{equation}
where the critical stress $\tau_c$ is a certain specified fraction of the water pressure in the subglacial hydrological system.
Sliding laws in icepack are not expressed directly, but rather as the the derivative of an action functional.
To implement the Schoof sliding law we need to know the antiderivative of equation \eqref{eq:schoof-sliding}.
Using a computer algebra system, we found that the antiderivative of this expression in terms of hypergeometric functions.
The Unified Form Language has several transcendental functions (sine, cosine, exponential, etc.), but it does not currently support hypergeometric functions.
Instead, we implemented a sliding relation that exhibits the important features of the Schoof law, i.e. it behaves like an $m = 3$ power law at low sliding speeds and $m = \infty$ at high sliding speeds, but which is more tractable algebraically.
Knowing the critical stress $\tau_c$ and the friction coefficient $C$, which has units of stress $\times$ speed${}^{-1/m}$, we can define a \emph{critical speed} $u_c$ as
\begin{equation}
    u_c = C^{-m}\tau_c^m.
\end{equation}
The power dissipation density for the Schoof-type sliding law that we use is
\begin{equation}
    P = \tau_c\left\{\left(u_c^{\frac{1}{m} + 1} + |u|^{\frac{1}{m} + 1}\right)^{\frac{m}{m + 1}} - u_c\right\}
    \label{eq:power-dissipation-modified-schoof-sliding}
\end{equation}
Figure \ref{fig:sliding-laws} shows a comparison of the original Schoof sliding law and the sliding law that arises as the derivative of the functional in equation \eqref{eq:power-dissipation-modified-schoof-sliding}.
The two have the same asymptotic behavior when the speed is much smaller or much larger than the critical speed; they differ in a relatively small range around the critical speed.
The relative difference in basal shear stress between the two sliding laws is less than 10\% throughout the entire range.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/sliding/sliding-law.png}
    \caption{The Weertman, Schoof, and modified Schoof sliding law of equation \eqref{eq:power-dissipation-modified-schoof-sliding}.
    The critical speed and shear stress are $u_c = 250$ m/year and $\tau_c = 100$ kPa.}
    \label{fig:sliding-laws}
\end{figure}

A sample of the source code implementing both of these approaches is shown in \textcolor{red}{Figure X}.
To change the sliding law, users only need to pass one function or the other to the model object at initialization.
Users do not need to implement a subclass that overrides some parent method.
This approach would be idiomatic in C++, but it requires some facility with object-oriented programming that a non-expert might lack.

Figure \ref{fig:mismip} shows the outcome of the MISMIP+ experiment performed using icepack.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/mismip/steady-state.png}
    \caption{The steady state thickness and velocity of the MISMIP+ experimental setup with the Weertman sliding law.}
    \label{fig:mismip}
\end{figure}

Using variational principles to express all constitutive laws is less flexible than specifying the sliding law directly and this is a distinct disadvantage.
We were able to implement a sliding law that exhibits many of the characteristics of the Schoof sliding law.
\citet{asay2016experimental} also suggest using a sliding law that transitions sharply to exact plasticity above the critical speed.
Expressing this sliding law in UFL requires a conditional in the velocity and is thus no longer differentiable.
This lack of differentiability makes the forward solver crash.
The numerical advantages of using variational principles are so great, however, that we view this tradeoff as acceptable.


\subsection{Synthetic ice sheet}
As a second test case for icepack, we ran an experiment inspired by \cite{kessler2008fjord}. In the original work, the authors couple an ice-flow model with simple models for bed-erosion, calving, and \textcolor{red}{glacial isostatic adjustment (GIA)} to investigate the formation of deep fjords that are characteristic of coastlines on Baffin Island, Greenland, and British Columbia, among others. Their first experiment is set in an idealized circular domain that contains a bedrock plateau rimmed by a ridge that is studded with four valleys. They find that fjords become well-developed after about one million years and that ice velocities are highest in these fjords. 

Similar to \cite{kessler2008fjord}, we use the shallow ice model; however, we do not couple it to bed-erosion, calving, and GIA models. We initialize the experiment with a simple, unrealistic ice sheet placed on the bed topography \textcolor{red}{(figure X)}. We let the ice sheet evolve without climate forcing for 500 years until it is near equilibrium. The time it takes to reach equilibrium is much shorter than the \cite{kessler2008fjord} experiment because the bedrock is static. The first part of our simulation is an exponential relaxation towards equilibrium. A velocity pattern emerges that is similar to results from \cite{kessler2008fjord}, with the highest velocities where ice is constricted through the deepest valleys \textcolor{red}{(figure X)}. In and upstream of the valleys, the surface is drawn down due to the elevated export of ice \textcolor{red}{as shown in figure X}.  

The ice-flow model chosen for this simulation is computationally cheap compared to the other ice-flow models, such that it can be used to simulate an ice sheet over thousands of years. By simply switching between ice-flow models, icepack is able to simulate a range of glaciological conditions over a range of timescales and spatial scales. For example, icepack can be used to simulate a small domain dominated by an ice stream, an ice catchment that includes slow-moving interior ice and a floating ice shelf, or, as in this example, an entire ice sheet. 

\subsection{Larsen C Ice Shelf}

To demonstrate the inverse solver, we will estimate the rheology of the Larsen C Ice Shelf in the Antarctic Peninsula from observational data.
Several recent studies have focused on Larsen C because it may be unstable in the warmer climate of the coming decades.
From January to March of 2002, the neighboring Larsen B Ice Shelf disintegrated due to surface melt pond-induced fracture \textcolor{red}{check that this is the currently-accepted explanation and cite}, and this mechanism could also lead to the breakup of Larsen C.
One of the key factors affecting the stability of ice shelves is the presence of marine ice -- seawater that freezes onto the base of an ice shelf -- in the suture zones where two flow units meet \citep{kulessa2014marine}.
Marine ice is warmer than meteoric ice and usually includes brine pockets, which are discernible in radio echo sounding measurements as the absence of reflection from the ice shelf base \citep{holland2009marine}.
This warmer and impurity-laden ice is more ductile and thus less prone to fracture than cold and brittle meteoric ice.
Ocean models predict that marine ice forms under Larsen C as well \citep{holland2009marine}.
By estimating the material rigidity of an ice shelf, we can constrain where marine ice may be forming.


\subsubsection{Data}

We used the InSAR phase-based ice velocity map from \citet{mouginot2019continent}.
This dataset has nominal errors over the Larsen Ice Shelf between \textcolor{red}{find it}.
We used the recently-released BedMachine map of the thickness of Antarctica \citep{morlighem2019deep}.
This data product improves on existing thickness maps for the continent by using the mass conservation law, together with measurements of the velocity, surface elevation, and surface mass balance, to improve thickness estimates where few measurements are available.

Existing work on glaciological inverse problems uses the mismatch between the computed and observed velocity fields as part of the objective functional.
The effect of thickness errors is studied largely through a posteriori validation \citep{joughin2004basal, larour2005rheology}.
Errors in thickness or surface slope can be large enough that it might be impossible to fit the velocity measurements to the degree that statistical theory predicts \citep{macayeal1995basal}.
The velocity measurements themselves might have significant outliers, in which case using the usual weighted sum of squared misfits as an error metric will give poor results.
For these reasons, some studies have explored alternative objective functionals \citep{morlighem2010spatial}.
We have opted to use the regularized $L^1$-type error metric
\begin{equation}
    E(u - u^o) = \int_\Omega\left(\sqrt{\frac{|u - u^o|^2}{\sigma^2} + \gamma^2} - \gamma\right)\ud x.
    \label{eq:l1-error-metric}
\end{equation}
This error metric approaches the usual weighted sum of squared errors as $\gamma \to \infty$, and approaches the sparsity-promoting $L^1$ error metric as $\gamma \to 0$.
For finite, positive values of $\gamma$ this error metric is robust to non-normality or a small fraction of outliers \citep{barron2019general}.

\citet{adusumilli2018variable} used surface elevation measurements from multiple satellite altimeters, together with firn density estimates from a climate model and tide height estimates, to compile a time series of ice thickness change over the Larsen Ice Shelf for the past 23 years.
This same approach can be used to derive an improved estimate the thickness of the ice shelf from, e.g. the REMA surface elevation dataset.
Future work will focus on this and other methods to assimilate more accurate thickness data and to explicitly account for the statistical errors in this field.


\subsubsection{Parameterization}

The rheology parameter of an ice shelf is strictly positive.
The optimization algorithm, however, can explore unphysical regions of parameter space without some a priori constraint on what values are reasonable.
Rather than try to solve an inequality-constrained problem, most studies in glaciology instead re-parameterize the problem in terms of some auxiliary field in such a way that the rheology is manifestly positive.
In this case we will use the parameterization
\begin{equation}
    A = A_0e^{\theta}
\end{equation}
and estimate $\theta$.
The inverse solver calculates the derivative of the objective functional symbolically and is thus agnostic to the particular parameterization.
The only information that the user needs to pass is the name of the arguments to the forward model representing the parameter and the observed field so that these can be passed by keyword.


\subsubsection{Results}

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/larsen/parameter.png}
    \caption{Left: Inferred fluidity parameter $\theta$.
    Lower values indicate more deformable ice.
    Right: stream plot of ice velocity computed from this fluidity parameter.}
    \label{fig:larsen}
\end{figure}

The inferred parameter field $\theta$ is shown in figure \ref{fig:larsen}.
The algorithm detects areas of much lower ice rigidity around highly damaged ice.
This feature is especially apparent around the large rift emanating from the Gipps Ice Rise, as well as the crevassed areas upstream.
We find other areas of low rigidity in the suture zones where two flow units converge and where marine ice tends to form, releasing heat to the ice shelf, exactly as observed in \citet{holland2009marine}.
Finally, the inferred rheology field reproduces features that have already been found in previous studies of Larsen C Ice Shelf \citep{khazendar2011acceleration}.

The final value of the model-data misfit \eqref{eq:l1-error-metric} matches the value we would expect if the velocity errors actually came from this probability distribution.
In a separate computational experiment, we used the older bedmap2 ice thickness map instead of BedMachine \citep{fretwell2013bedmap2}.
We were unable to achieve the same model-data misfit using bedmap2 at the same grid resolution with any regularization parameter.


\section{Usability}

One of the main goals for icepack is to create a tool that is accessible to researchers who might not be experts in scientific computing.
Previous work on numerical modeling of glacier flow has focused largely on technical details of the models themselves -- does a given solver converge with the accuracy expected from finite element theory, does it scale to large numbers of processors, can models accurately predict grounding line retreat, etc.
The fallible human learning to use the model is largely absent from the discussion.
For graduate students or other researchers who are not experts in computational physics, the difficulty of learning to use a particular modeling tool may be more of a rate-limiting factor than the speed or efficiency of the model.

The field of \emph{human-computer interaction} (HCI) asks how we can design software that is easiest to learn and use effectively.
In the following, we will describe some of the design choices in icepack and how they relate to what HCI researchers call the \emph{cognitive dimensions of notations}.
\citet{green1996usability} introduced this concept to assess the usability of visual programming languages, but the criteria they laid out in this paper have been used to analyze software systems across many disciplines.

\textbf{Consistency: After a user learns part of the software, can they guess the remaining parts?}
Each of the model objects in icepack is a class with a method ending in \texttt{solve} that takes in keyword arguments for the various input fields and options for things like boundary conditions.
Users already familiar with, say, the \texttt{IceStream} class can then use the \texttt{HeatTransport} class under the assumption that the input fields -- the current temperature $T$, ice velocity $u$, and basal melt rate $m$ -- are passed as keyword arguments with the same name as the fields themselves.
This obviates the need for consulting the documentation or examples.

\textbf{Progressive evaluation: How easily can users get feedback during their use of the software?}
Progressive evaluation is the main advantage of having a user interface in Python or another interpreted language, as opposed to using compiled programs that must run all at once.
Icepack includes a suite of example programs that demonstrate all of the main functions of the package.
These demos are formatted as Jupyter notebooks, a document format that includes code, figures, and explanatory text with typeset mathematics that runs interactively in a web browser \citep{kluyver2016jupyter}.
A notebook is a sequence of cells, each of which consists of either code or text.
The code cells can be executed one-at-a-time and this enables users to insert diagnostics in each cell as they go.
Most importantly, the notebook format also integrates the plotting library matplotlib so that figures created in each cell appear directly beneath that cell as it is executed.
The ability to visualize the current state of the simulation at every step is a powerful tool for debugging and sanity-checking.
\textcolor{red}{Picture of an executed jupyter notebook.}
The interface for icepack also supports inspection of partial results in other ways.
Running a simulation amounts to writing a loop that alternates prognostic and diagnostic solves.
Users can add arbitrary code to this loop for sanity checking or feedback on progress, or they can manually step through the simulation one iteration at a time.
Other packages only support a more coarse-grained view.
The user specifies the starting and ending time of a simulation, and the degree of feedback is hard-coded into the package itself.


\textbf{Abstraction gradient: What are the levels of abstraction exposed by the library?
Can irrelevant details be hidden?}
The API for icepack has been designed so that the users only need to decide what problem to solve and not how to solve it.
Where a choice does concern more the ``how'' than the ``what'', we use a sensible default that biases for correctness rather than speed.
For example, the Newton solver uses a direct factorization method to solve the linear system for the search direction because factorization requires no tuning whereas iterative methods do.
A user interested in achieving greater runtime performance can pass additional keyword arguments instead specifying, say, the preconditioned conjugate gradient method.
This choice is of interest mostly to advanced users so we keep the linear solver method as a default argument.
In so doing, we avoid confronting novice users with options that they might not understand.

Advanced users who wish to tune solver performance for large simulations will need some way to make choices about algorithms.
For example, a more advanced user might choose the GMRES iterative solver together with an incomplete LU preconditioner to solve linear systems.
The solver classes, as opposed to the model classes, provide the interface for making these kinds of algorithmic choices.
While alternative solvers might offer faster runtime performance than direct factorization, they also requires making additional choices choices -- how often to restart GMRES?
How much fill-in to allow in the incomplete factorization?
Many glaciologists do not have the background in numerical linear algebra to know that adjusting these parameters could make the difference between solver convergence or breakdown.
Similarly, users might want to select between different discretization strategies for the Stokes equations, which must be chosen carefully in order to satisfy the Ladyzhenskaya-Babu\v{s}ka-Brezzi (LBB) conditions \citep{boffi2013mixed}.
When using Galerkin least-squares \textcolor{red}{check that's actually what it is} stabilization of the weak form, the user has to pick a value of the stabilization parameter.
Determining exactly what value of this parameter is necessary to guarantee stability is a subtle problem, even more so for the kinds of highly anisotropic meshes that are commonly encountered in 3D glacier flow modeling.
If the solver fails to converge, it might not be obvious even to an expert whether the problem lies with the stabilization or the aforementioned parameters of the linear solver.


\section{Discussion}



\bibliographystyle{plainnat}
\bibliography{icepack.bib}

\end{document}
